---
title: ELK éƒ¨ç½²å®è·µæŒ‡å—~
date: 2024-10-21T21:10:00.000Z
lastmod: 2024-10-21T21:10:00.000Z
description: ELK éƒ¨ç½²å®è·µæŒ‡å—~
tags: [ "ELK" ]
categories : [ "ELK" ]
lazyBanner : "/imglazy/blog/defaultbanner-lazy.webp"
banner : "/img/blog/defaultbanner.webp"
lazyCardImg : "/imglazy/blog/elk-lazy.webp"
cardImg : "/img/blog/elk.webp"
---

# ğŸ

æ–‡ç« å°é¢æ¥è‡ª[æ®˜å¤œ ZANYA-âœ¨](https://www.pixiv.net/artworks/113134444)

æœ€è¿‘ç»ˆäºå»äº†ç†æƒ³çš„å…¬å¸~

æ˜¯æ—¶å€™ç»§ç»­æ•´ç†æ•´ç†è¿‡å»å·¥ä½œçš„ç¬”è®° share share äº†

è¿™ç¯‡ä»æœ€åº•å±‚çš„æ—¥å¿—é‡‡é›†åˆ°å±•ç¤ºå¯¹ELKï¼ˆ7.5.1ï¼‰åšäº†å®Œæˆçš„éƒ¨ç½²æµ‹è¯•æ¢³ç† å¯¹ç”Ÿäº§æœ‰ä¸€å®šå€Ÿé‰´æ„ä¹‰

ä»‹ç»é¡ºåºæ˜¯ Filebeat -> Kafka -> Logstash -> ElasticSearch -> Kibana

è™½ç„¶å®è·µç‰ˆæœ¬æœ‰äº›è€ ä½†æœ€å…³é”®å®ƒä¸è¦é’± ğŸ‘» 

å¦‚æœä½ éœ€è¦ä»å¤´æ­å»ºç™½å«–ä¸€å¥—æ—¥å¿—æ”¶é›†ç³»ç»Ÿ å¸Œæœ›æœ¬ç¯‡æ–‡ç« ä¼šå¯¹ä½ æœ‰ç”¨ï¼

## Filebeat

æµ‹è¯•éƒ¨ç½²æ”¶é›†æ—¥å¿—çš„beatsç»„ä»¶ï¼Œä½¿ç”¨filebeatç‰ˆæœ¬ 7.5.1



### èµ„æºä¸‹è½½

å®˜æ–¹æ–‡æ¡£ï¼š[Filebeat overview | Filebeat Reference[7.5] | Elastic](https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-overview.html)

ä¸‹è½½åœ°å€ï¼š[Filebeat 7.5.1 | Elastic](https://www.elastic.co/cn/downloads/past-releases/filebeat-7-5-1)



### éƒ¨ç½²

```bash
mkdir -p /app/logs/filebeat
cd /app
tar -zxvf filebeat-7.5.1-linux-x86_64.tar.gz
mv filebeat-7.5.1-linux-x86_64 filebeat
cd filebeat/
mkdir -p config
cd config
vim filebeat.yml
vim inputs.yml
```

å…·ä½“é…ç½®å¦‚ä¸‹

> é…ç½®å«ä¹‰å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£
>
> [filebeat.reference.yml | Filebeat Reference [7.5] | Elastic](https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-reference-yml.html)

filebeat.yml

```yaml
filebeat.config.inputs:
  enabled: true
  path: /app/filebeat/config/inputs.yml
  reload.enabled: true
  reload.period: 1m
max_procs: 1
output.kafka:
  hosts: ["192.168.202.131:9092"]
  topic: "%{[topic]}"
logging.to_files: true
logging.files:
  path: /app/logs/filebeat/
  name: filebeat.log
  keepfiles: 2
```

filebeat.yml éƒ¨åˆ†é…ç½®å¤‡æ³¨

* reload
  * inputs.yml è°ƒæ•´å filebeat å¯ä»¥åŠ¨æ€åŠ è½½ 
  * [Live reloading | Filebeat Reference [7.5] | Elastic](https://www.elastic.co/guide/en/beats/filebeat/7.5/_live_reloading.html)

* max_procs 
  * åŒæ—¶è¿è¡Œçš„ cpu æ•°ï¼Œå»ºè®®è°ƒä½é˜²æ­¢æ—¥å¿—æ”¶é›†å ç”¨æœºå™¨è¾ƒå¤šçš„cpuèµ„æº



inputs.yml

```yaml
- type: log
  paths: [/app/logs/nginx/access*.log, /app/nginx/logs/error.log, /app/sunline/nginx/logs/error.log]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: NGINX-LOGS, type: nginx,
    az: xx}
  fields_under_root: true
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m
```

inputs.yml éƒ¨åˆ†é…ç½®å¤‡æ³¨

* fields
  * å¢åŠ é¢å¤– å­—æ®µï¼ˆæ”¶é›†è¿›esï¼‰
* fields_under_root
  * å¢åŠ å­—æ®µåˆ°é¡¶çº§ è€Œä¸æ˜¯äºŒçº§ï¼ˆç±»ä¼¼ json åµŒå¥— å¦‚æœè®¾ç½®ä¸ºfalse åˆ™jsonç»“æ„ç±»ä¼¼ "fields"ï¼š{"app": "test"} è€Œä¸æ˜¯ "app": "test"ï¼‰
* clean_inactive
  * è¶…è¿‡è®¾ç½®æ—¶é—´åˆ™ä¼šä»æ³¨å†Œï¼ˆè®°å½•æ”¶é›†çš„æ–‡ä»¶å’Œä½ç½®ä¿¡æ¯ï¼‰è¡¨ä¸­åˆ é™¤ è®¾ç½®æ—¶é—´å¿…é¡»å¤§äº ignore_older å’Œ scan_frequency
* ignore_older
  * ä¸ä¼šæ”¶é›† ä¿®æ”¹æ—¶é—´ è¶…è¿‡ è®¾ç½®æ—¶é—´èŒƒå›´çš„æ–‡ä»¶
* close_inactive
  * è¶…è¿‡æ—¶é—´æ–‡ä»¶æœªè¢«ä¿®æ”¹å…³é—­è¯»å–æ–‡ä»¶å¥æŸ„ï¼Œä¸‹æ¬¡æ£€æµ‹åˆ°æ–‡ä»¶æ›´æ–°ï¼Œä»è®°å½•çš„æœ€åä½ç½®è¯»å–
* close_renamed
  * å¦‚æœæ–‡ä»¶è¢«é‡å‘½åï¼ˆæ¯”å¦‚è¿›è¡Œæ—¥å¿—æ»šåŠ¨ï¼‰ï¼Œè®¾ç½®ä¸º true åˆ™å…³é—­æ”¶é›†
* close_removed
  * å¦‚æœæ–‡ä»¶è¢«åˆ é™¤ï¼Œè®¾ç½®ä¸º true åˆ™å…³é—­æ”¶é›†
* close_timeout
  * filebeatè¯»å–å™¨çš„æœ€é•¿ç”Ÿå‘½å‘¨æœŸï¼Œè¶…è¿‡åˆ™ä¼šå…³é—­ï¼Œå†ä¸‹æ¬¡è¯»å–æ—¶é‡æ–°å¼€å§‹è®¡æ—¶



åˆ›å»ºå¯åŠ¨è„šæœ¬

```bash
cd /app/filebeat
vim filebeat.sh
```

filebeat.sh

```shell
#!/bin/bash

PARAMETER=""

if [ $# -gt 0 ];then
    PARAMETER=$*
fi

KEYWORDS="/app/filebeat/filebeat"

gspPID=0

getGspPID(){
    pid=`ps -ef|grep $KEYWORDS | grep -v grep | grep -v "filebeat.sh" | awk '{print $2}'`
    if [ -n "$pid" ]; then
        gspPID=$pid
    else
        gspPID=0
    fi
}

gspShutDown(){
    getGspPID
    if [ $gspPID -ne 0 ]; then   
        kill $gspPID
        clear
        echo "filebeat å·²åœæ­¢"
    else  
        echo "filebeat æ²¡æœ‰å¯åŠ¨"  
    fi  
}  

gspStartup(){
    getGspPID
    if [ $gspPID -ne 0 ]; then
        echo "ç³»ç»Ÿå·²ç»å¯åŠ¨"
    else  
        chmod 644 /app/filebeat/config/filebeat.yml
        nohup nice -n 19 /app/filebeat/filebeat -c /app/filebeat/config/filebeat.yml > /dev/null 2>&1 &
    fi 
    getGspPID
    if [ $gspPID -ne 0 ]; then
        taskset -cp 0 $gspPID
    else
        echo "filebeatæœªå¯åŠ¨"
    fi
}

clear

if [ "xstart" == "x$1" ]; then
        gspStartup
else
   if [ "xstop" == "x$1" ]; then
        gspShutDown
   else
        echo "å¯åŠ¨æŒ‡ä»¤ï¼šfilebeat.sh start/stop"
   fi
fi
```

å¯åŠ¨filebeat

```bash
sh filebeat.sh start
```

å¦‚æœéœ€è¦åœæ­¢

```bash
sh filebeat.sh stop
```



### æ—¥å¿—æ”¶é›†æµ‹è¯•

è¿›è¡Œæ—¥å¿—æ”¶é›†æµ‹è¯•ä¹‹å‰ï¼Œç¡®ä¿å·²ç»æŒ‰ç…§æ–‡æ¡£å®Œæˆäº† filebeat å’Œ kafka çš„éƒ¨ç½²

è¿›è¡ŒNGINXæ—¥å¿—æ”¶é›†çš„æµ‹è¯•

æ ¹æ® filebeat é…ç½®æ–‡ä»¶ï¼Œfilebeat æ”¶é›† /app/logs/nginx/ ä¸‹çš„æ‰€æœ‰ access*.log

æ‰‹åŠ¨åˆ›å»ºæµ‹è¯• access log

```bash
mkdir -p /app/logs/nginx/
vim /app/logs/nginx/access-test4.log
```

å½•å…¥çš„NGINXæ—¥å¿—æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼ˆå…³äºNGINX æˆ‘æœ‰å¦å¤–ä¸€ç¯‡æ–‡ç« è¯¦ç»†è®°å½•äº†ç›¸å…³çš„å†…å®¹ NGINXæ—¥å¿—ä¹Ÿæ˜¯ç»è¿‡è°ƒæ•´åçš„æ ¼å¼ï¼‰

```markdown
[2024-05-24T15:53:06+08:00] - 103.212.99.122:60158 "HTTP/1.1 GET http://uptime.lkarrie.com/configs.php?ote" 301 162 0.000 264 "-" "Mozilla/5.0 (Windows NT 10.0; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0" "-" "-" - -
```

å½•å…¥æˆåŠŸåæ£€æŸ¥ filebaet æ—¥å¿—ï¼Œæ˜¯å¦æ”¶é›†äº† access-test4.log æ–‡ä»¶

```bash
cd /app/logs/filebeat
grep Har * | grep test4
```

![filebeat-test](https://image.lkarrie.com/images/2024/10/22/filebeat-test.png)

filebeat æˆåŠŸ Harvester ç›¸å…³æ–‡ä»¶å³æ­£å¸¸

ä¸Šè¿°çš„æ£€ç´¢æ–¹å¼ä¹Ÿå¯ä»¥éªŒè¯ filebeat æ˜¯å¦æ”¶é›†äº†å…¶ä»–æ—¥å¿—æ–‡ä»¶



### è¡¥å……å†…å®¹

ä»…æ˜¯æ­å»ºæµ‹è¯•ç¯å¢ƒï¼Œå¯ä»¥è·³è¿‡è¿™éƒ¨åˆ†å†…å®¹

å®é™…åœ¨æ”¶é›†æ—¥å¿—ä¼šæœ‰å¤šç§ç±»å‹çš„æ—¥å¿—æ¯”å¦‚ åº”ç”¨çš„Javaæ—¥å¿—ï¼ŒNGINXæ—¥å¿—ï¼Œæ•°æ®åº“æ—¥å¿—ï¼Œç³»ç»Ÿæ—¥å¿—ç­‰ï¼Œåœ¨å®è·µè¿‡ç¨‹ä¸­å¯ä»¥æŒ‰ç…§ç±»å‹åœ¨ inputs.yml ä¸­åŒºåˆ†ä¸ºä¸åŒ topicï¼Œå…·ä½“å¦‚ä¸‹ï¼ˆä»…ä¾›å‚è€ƒ

```yaml
# æ”¶é›† JAVA åº”ç”¨æ—¥å¿—
- type: log
  paths: [/app/logs/**/*.log]
  exclude_files: [^\/app\/logs\/nginx\/.*, ^\/app\/logs\/net-device\/.*]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: APP-VM-LOGS, type: app,
    az: xx}
  fields_under_root: true
  multiline.pattern: ^\[
  multiline.negate: true
  multiline.match: after
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m

# æ”¶é›† éœ€è¦è¿›è¡Œæ—¥å¿—å‘Šè­¦çš„ æ–‡æœ¬æ–‡ä»¶
- type: log
  paths: [/app/logs/**/*.alert]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: LOG_ALERT, type: alert,
    az: xx}
  fields_under_root: true
  multiline.pattern: ^\[
  multiline.negate: true
  multiline.match: after
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m

# æ”¶é›†ç³»ç»Ÿæ—¥å¿— 
- type: log
  paths: [/var/log/messages, /var/log/sftp.log, /var/named/data/named.run]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: SYS-LOGS, type: sys,
    az: xx}
  fields_under_root: true
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m
  
# æ”¶é›† oracle æ—¥å¿—  
- type: log
  paths: [/grid/grid_base/diag/crs/*/crs/trace/ocssd.trc, /grid/grid_base/diag/crs/*/crs/trace/crsd.trc,
    /oracle/diag/rdbms/*/*/trace/alert_*.log]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: DB-LOGS, type: oracle,
    az: xx}
  fields_under_root: true
  multiline.pattern: ^[0-9]{4}-[0-9]{2}-[0-9]{2}
  multiline.negate: true
  multiline.match: after
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m
  
# æ”¶é›† postgresql æ—¥å¿—
- type: log
  paths: [/pglog/postgresql-*.csv, /pgbak/*/log/bak.log]
  encoding: utf-8
  fields: {remote_ip: 192.168.202.131, system: test, app: test, topic: DB-LOGS, type: postgresql,
    az: xx}
  fields_under_root: true
  multiline.pattern: ^[0-9]{4}-[0-9]{2}-[0-9]{2}
  multiline.negate: true
  multiline.match: after
  clean_inactive: 25h
  ignore_older: 24h
  close_inactive: 10m
  close_renamed: false
  close_removed: true
  close_timeout: 5m
```



å¦å¤–åœ¨çº¿ä¸Šç¯å¢ƒä¸­ï¼Œé€šå¸¸åº”ç”¨éƒ½ä¼šå¯¹æ—¥å¿—è¿›è¡Œæ»šåŠ¨æ›´æ–°ï¼Œå§‹ç»ˆä¿æŒæœ¬åœ°çš„æ—¥å¿—æ–‡ä»¶æ—¶é—´åœ¨æ»šåŠ¨å‘¨æœŸå†…ï¼Œè¿™æ ·å°±ä¼šäº§ç”Ÿä¸€ä¸ªé—®é¢˜ï¼Œåœ¨æ—¥å¿—æ»šåŠ¨è§¦å‘çš„æ—¶ç‚¹ä¼šä¸ä¼šäº§ç”Ÿæ—¥å¿—ä¸¢å¤±çš„é—®é¢˜

è¿™é‡Œç›´æ¥è¯´ç»“è®º

ä»¥ logrotate å¯¹å¤§æ—¥å¿—æ–‡ä»¶è¿›è¡Œåˆ‡å‰²ä¸ºä¾‹ï¼Œ**æ—¥å¿—æ–‡ä»¶ inode ä¸ä¼šå˜åŒ–çš„æƒ…å†µä¸‹å¦‚æœè¿›è¡Œå‹ç¼©åˆ‡å‰²ä¼šå¯¼è‡´æ—¥å¿—ä¸¢å¤±**

åˆ‡å‰²æ–¹æ³•ï¼š

copytruncateï¼šåˆ›å»ºæ—¥å¿—æ–‡ä»¶å‰¯æœ¬å¹¶æˆªæ–­åŸå§‹æ—¥å¿—æ–‡ä»¶ï¼ˆæ—¥å¿—æ–‡ä»¶ inode ä¸ä¼šæ”¹å˜ï¼‰

createï¼šåˆ›å»ºæ–°çš„æ—¥å¿—æ–‡ä»¶ï¼ŒåŸæ–‡ä»¶è¢«mvæˆæ—§æ–‡ä»¶ï¼ˆæ—¥å¿—æ–‡ä»¶ inode ä¼šæ”¹å˜ï¼‰

åœºæ™¯ï¼š

* å½“ä½¿ç”¨copytruncateæ»šåŠ¨ä¸ºgzæ–‡ä»¶ xxx.log  xxx.log.1.gz  copytruncate **ä¼šå¯¼è‡´æ—¥å¿—ä¸¢å¤±**

Logrotateé…ç½®

```Shell
/app/logs/test.log
{
  rotate 20
  daily
  compress
  copytruncate
}
```

* å½“ä½¿ç”¨createæ»šåŠ¨ä¸ºgzæ–‡ä»¶ xxx.log  xxx.log.1.gz  copytruncate **æ—¥å¿—ä¸ä¼šä¸¢å¤±**

Logrotateé…ç½®

```Shell
/app/logs/test.log
{
  rotate 20
  daily
  compress
  create 644 root root
}
```

* å½“ä½¿ç”¨copytruncateæ»šåŠ¨ä¸ºæ™®é€šå¤‡ä»½æ–‡ä»¶ xxx.log  xxx.log.1 filebeat æ”¶é›† xxx.log*  **æ—¥å¿—ä¸ä¼šä¸¢å¤±**

Logrotateé…ç½®

```Shell
/app/logs/test.log
{
  rotate 20
  daily
  copytruncate
}
```

* å½“ä½¿ç”¨createæ»šåŠ¨ä¸ºæ™®é€šå¤‡ä»½æ–‡ä»¶ xxx.log  xxx.log.1 filebeat æ”¶é›† xxx.log*  **æ—¥å¿—ä¸ä¼šä¸¢å¤±**

Logrotateé…ç½®

```Shell
/app/logs/test.log
{
  rotate 20
  daily
  create 644 root root
}
```


## Kafka

æµ‹è¯•éƒ¨ç½²æ”¶é›†filebeatæ¨é€æ—¥å¿—ï¼Œbrokerå’Œzookeeprï¼Œå‡éƒ¨ç½²å•èŠ‚ç‚¹

æµ‹è¯•ç‰ˆæœ¬ï¼š

* Kafka 2.12-2.2.0

* Zookeeper 3.4.13

å¦‚æœéœ€è¦ä½¿ç”¨å½“å‰ç‰ˆæœ¬çš„Kafkaï¼ˆä¾‹å¦‚ Javaï¼‰ï¼Œå®¢æˆ·ç«¯ç‰ˆè¦æ±‚ 2.2.0


### èµ„æºä¸‹è½½

ä¸‹è½½åœ°å€

- Kafka

  * [Index of /dist/kafka/2.2.0 (apache.org)](https://archive.apache.org/dist/kafka/2.2.0/)

  * ä¸‹è½½ç‰ˆæœ¬ï¼škafka_2.12-2.2.0.tgz 
- Zookeeper

  * [Index of /dist/zookeeper/zookeeper-3.4.13 (apache.org)](https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/)
  * ä¸‹è½½ç‰ˆæœ¬ï¼šzookeeper-3.4.13.tar.gz



### éƒ¨ç½²

éƒ¨ç½²èŠ‚ç‚¹

| éƒ¨ç½²      | ip              | ç«¯å£                                                         |
| --------- | --------------- | ------------------------------------------------------------ |
| broker    | 192.168.202.131 | 9092                                                         |
| zookeeper | 192.168.202.131 | 2181ï¼ˆæœåŠ¡ç«¯å£ï¼‰2888ï¼ˆé›†ç¾¤å†…æœºå™¨é€šè®¯ä½¿ç”¨Leader å’Œ Follower ä¹‹é—´æ•°æ®åŒæ­¥ä½¿ç”¨çš„ç«¯å£å·ï¼ŒLeader ç›‘å¬æ­¤ç«¯å£ï¼‰3888ï¼ˆé€‰ä¸¾leaderç«¯å£ï¼‰ |



#### ç¯å¢ƒè¦æ±‚

* Jdk 1.8

ä½ç‰ˆæœ¬éœ€è¦å¸è½½é‡æ–°å®‰è£…ç¬¦åˆè¦æ±‚çš„ç‰ˆæœ¬ï¼ˆæµ‹è¯•è™šæ‹Ÿæœºä¸º jdk1.7 æ‰€ä»¥å¸è½½é‡è£…

```bash
rpm -qa | grep jdk
yum -y remove copy-jdk-configs-3.3-10.el7_5.noarch
yum search java | grep jdk
yum install java-1.8.0-openjdk-devel.x86_64 -y
java -version
```

å‡†å¤‡å®‰è£…ç›®å½•ã€æ—¥å¿—ç›®å½•ã€å­˜å‚¨ç›®å½•ï¼ˆä¸Šä¼ å®‰è£…åŒ…åˆ° /app ç›®å½•ä¸‹

```bash
cd /app
tar -zxvf zookeeper-3.4.13.tar.gz
mv zookeeper-3.4.13 zookeeper
rm zookeeper-3.4.13.tar.gz
mkdir -p /app/logs/zookeeper
mkdir -p /app/data/zookeeper

tar -zxvf kafka_2.12-2.2.0.tgz
mv kafka_2.12-2.2.0 kafka
rm kafka_2.12-2.2.0.tgz 
mkdir /app/logs/kafka
mkdir /app/data/kafka
```



#### Zookeeperéƒ¨ç½²

```bash
cd /app/zookeeper/config
vim zoo.cfg
```

å•èŠ‚ç‚¹ zoo.cfg é…ç½® å¦‚ä¸‹

```properties
#zkæœåŠ¡ç«¯ä¸å®¢æˆ·ç«¯å¿ƒè·³æ—¶é—´
tickTime=2000
#æ•°æ®ç›®å½•
dataDir=/app/data/zookeeper/
#æœåŠ¡ç«¯å£
clientPort=2181
```

ä¿®æ”¹æ—¥å¿—é… è°ƒæ•´æ—¥å¿—åˆ°å¯¹åº”ç›®å½•

```properties
# Define some default values that can be overridden by system properties
zookeeper.root.logger=INFO, CONSOLE
zookeeper.console.threshold=INFO
zookeeper.log.dir=/app/logs/zookeeper
zookeeper.log.file=zookeeper.log
zookeeper.log.threshold=DEBUG
zookeeper.tracelog.dir=/app/logs/zookeeper
zookeeper.tracelog.file=zookeeper_trace.log

#
# ZooKeeper Logging Configuration
#

# Format is "<default threshold> (, <appender>)+
```

å¯åŠ¨

```bash
cd /app/zookeeper
# ä½¿ç”¨é»˜è®¤JVMå‚æ•°å¯åŠ¨
./bin/zkServer.sh start
```



#### è¡¥å……å†…å®¹

å¸¸ç”¨å‘½ä»¤

```properties
#å¯åŠ¨ï¼ˆé»˜è®¤è¯†åˆ« conf/zoo.cfgï¼‰
./bin/zkServer.sh start

#åœæ­¢
./bin/zkServer.sh stop

#é‡å¯
./bin/zkServer.sh restart

#æŒ‡å®šé…ç½®æ–‡ä»¶å¯åŠ¨
./bin/zkServer.sh --config zoo.cfgçš„ç›®å½• {start,stop,restart,status,upgrade,print-cmd,start-foreground}
```

å¦‚æœéœ€è¦è°ƒæ•´zookeeperå †å†…å­˜

```markdown
# åœ¨ conf ç›®å½•ä¸‹è®¾ç½®JVMå‚æ•°
cd /app/zookeeper/conf
vim java.env
# è°ƒæ•´å®Œæˆåé‡å¯ zookeeper
# å¯ä»¥é€šè¿‡ ps -aux | grep zookeeper æˆ–è€… jmap -heap pid æŸ¥çœ‹å †å†…å­˜å‚æ•°
```

java.env

```bash
export JVMFLAGS="-Xmx2g"
export JVMFLAGS="-Xms1g $JVMFLAGS"
```



å¦‚æœå°è¯•é›†ç¾¤éƒ¨ç½²ï¼Œzookeeper é…ç½®å¦‚ä¸‹ï¼ˆä»…ä¾›å‚è€ƒ

```properties
#zkæœåŠ¡ç«¯ä¸å®¢æˆ·ç«¯å¿ƒè·³æ—¶é—´
tickTime=2000
#leaderå’Œfolloweråˆå§‹åŒ–é€šä¿¡æ—¶é™
initLimit=10
#leaderå’Œfolloweré€šä¿¡æ—¶é™
syncLimit=5

#æ•°æ®ç›®å½•
dataDir=/app/data/zookeeper/
#æœåŠ¡ç«¯å£    
clientPort=2181

#å•æœºéƒ¨ç½² ä¸éœ€è¦é…ç½®
#é›†ç¾¤æ¨¡å¼ï¼Œserveråœ°å€
server.1=1.1.1.1:2888:3888
server.2=1.1.1.2:2888:3888
server.3=1.1.1.3:2888:3888

#å››å­—ç™½åå•
#4lw.commands.whitelist=*

#è·³è¿‡acl(aclé…ç½®é”™è¯¯åå¯ä¸´æ—¶å¼€å¯ä¿®æ”¹acl)
#skipAcl=true
```

ä½¿ç”¨é›†ç¾¤éƒ¨ç½²ï¼Œéœ€è¦åˆ†åˆ«åœ¨æ‰€æœ‰zookeeperèŠ‚ç‚¹é¢å¤–åˆ›å»ºmyid

```bash
#zookeeper èŠ‚ç‚¹1 æœºå™¨
echo 1 > /app/data/zookeeper/myid

#zookeeper èŠ‚ç‚¹2 æœºå™¨
echo 2 > /app/data/zookeeper/myid

#zookeeper èŠ‚ç‚¹3 æœºå™¨
echo 3 > /app/data/zookeeper/myid
```



#### Kafkaéƒ¨ç½²

```Java
cd /app/kafka/config
vim server.properties
```

brokeré…ç½®

```properties
#brokeråœ¨é›†ç¾¤ä¸­çš„å”¯ä¸€æ ‡è¯†
#æ¯å°brokeréœ€ä¸åŒ å¯ä»¥åˆ†åˆ«è®¾ç½® 0 1 2 3 ...
broker.id=0
#serveræš´éœ²æœåŠ¡ç«¯å£
listeners=PLAINTEXT://192.168.202.131:9092
advertised.listeners=PLAINTEXT://192.168.202.131:9092
#æ ¹æ®æœºå™¨cpuè°ƒæ•´
num.network.threads=3
#æ ¹æ®æœºå™¨cpuè°ƒæ•´
num.io.threads=8
#socketå‘é€ç¼“å­˜åŒºå¤§å°é™åˆ¶
socket.send.buffer.bytes=102400
#socketæ¥æ”¶ç¼“å†²åŒºå¤§å°é™åˆ¶
socket.receive.buffer.bytes=102400
#socketå¯è¯·æ±‚æ¶ˆæ¯ä½“æœ€å¤§é™åˆ¶
socket.request.max.bytes=104857600
#kafkaå­˜æ”¾æ¶ˆæ¯è·¯å¾„
log.dirs=/app/data/kafka
#é»˜è®¤å»ºç«‹topicåˆ†åŒºæ•°é‡
#å»ºè®®topicåˆ†åŒºæ•°ä¸kafkaèŠ‚ç‚¹æ•°ä¸€è‡´
num.partitions=1
#kafkaå®•æœºåï¼Œæ¢å¤æ•°æ®çº¿ç¨‹æ•°é‡è®¾ç½®ï¼›æ¯ä¸ªç›®å½•å ç”¨çš„çº¿ç¨‹æ•°é‡
num.recovery.threads.per.data.dir=1
#topicå‰¯æœ¬é»˜è®¤æ•°é‡
#å»ºè®®topicå‰¯æœ¬æ•°å¤§äºç­‰äº3
offsets.topic.replication.factor=1
#äº‹åŠ¡æ¶ˆæ¯å‰¯æœ¬æ•°é‡
transaction.state.log.replication.factor=1
#äº‹åŠ¡æ¶ˆæ¯å‰¯æœ¬å¤„äºisrçš„æœ€å°æ•°é‡
transaction.state.log.min.isr=1

# æ•°æ®æ–‡ä»¶ä¿å­˜æ—¶é—´
log.retention.hours=168
# æ—¥å¿—åˆ†æ®µé˜ˆå€¼ 1G
log.segment.bytes=1073741824
# æ•°æ®æ–‡ä»¶æ‰«æé—´éš”ï¼Œè¿‡æœŸæ—¶é—´æ–‡ä»¶è¿›è¡Œåˆ é™¤
log.retention.check.interval.ms=300000

# zookeeperé…ç½®
zookeeper.connect=localhost:2181
# zookeeperè¿æ¥è¶…æ—¶æ—¶é—´
zookeeper.connection.timeout.ms=6000
# æ¶ˆè´¹è€…ç»„é‡å¹³è¡¡åˆå§‹åŒ–å»¶è¿Ÿæ—¶é—´
group.initial.rebalance.delay.ms=0
```

æ—¥å¿—ç›®å½•ä¿®æ”¹

```bash
sed -i -e 's/${kafka.logs.dir}/\/app\/logs\/kafka/g' log4j.properties
```

å¯åŠ¨å’Œåœæ­¢

```bash
#å¯åŠ¨
nohup ./bin/kafka-server-start.sh ./config/server.properties  2>&1 &

# Java å †å†…å­˜ æŒ‰éœ€è°ƒæ•´ åœ¨è„šæœ¬ kafka-server-start.sh å†…
# é»˜è®¤ export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"

#åœæ­¢
./bin/kafka0server-stop.sh 
```

é…ç½®å¼€æœºè‡ªå¯ï¼ŒzookeepråŒæ ·å¯å‚è€ƒé…ç½®å¼€æœºè‡ªå¯åŠ¨

```markdown
crontab -e 
@reboot sh /app/kafka/bin/kafka-server-start.sh /app/kafka/config/server.properties
```



#### è¡¥å……å†…å®¹

è¡¥å……ä¸€ä»½æˆ‘å®é™…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ”¶é›†æ—¥å¿—ä¿¡æ¯æ‰€ä½¿ç”¨çš„é…ç½®ï¼ˆä»…ä¾›å‚è€ƒ

kafka-server-start.sh å†… jvm å‚æ•°

```shell
export KAFKA_HEAP_OPTS="-Xmx12G -Xms12G -XX:MaxDirectMemorySize=8G" 
```



broker

```properties
broker.id=0
listeners=PLAINTEXT://1.1.1.1:9092
advertised.listeners=PLAINTEXT://1.1.1.1:9092
listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
num.network.threads=16
num.io.threads=32
socket.send.buffer.bytes=10485760
socket.receive.buffer.bytes=10485760
socket.request.max.bytes=104857600
log.dirs=/app/data/kafka
num.partitions=3
auto.create.topics.enable=false
delete.topic.enable=false
offsets.topic.replication.factor=7
transaction.state.log.replication.factor=7
transaction.state.log.min.isr=2
log.retention.hours=24
log.segment.bytes=1073741824
log.retention.check.interval.ms=60000
zookeeper.connect=1.1.1.1:2181,1.1.1.2:2181,1.1.1.3:2181
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
```



è¡¥å……å¸¸ç”¨çš„å‘½ä»¤

```markdown
# åˆ›å»ºtopic
./bin/kafka-topics.sh --bootstrap-server 192.168.202.131:9092 --create --topic demo --partition 7 --replication-factor 2

# æŸ¥çœ‹topicè¯¦æƒ…
./bin/kafka-topics.sh --bootstrap-server 192.168.202.131:9092 --topic demo --describe

# æŸ¥çœ‹topicåˆ—è¡¨
./bin/kafka-topics.sh --bootstrap-server 192.168.202.131:9092 --list

# æ‰©å®¹åˆ†åŒº(åˆ†åŒºåªèƒ½æ‰©å®¹ï¼Œä¸èƒ½ç¼©å®¹)
./bin/kafka-topics.sh --bootstrap-server 192.168.202.131:9092  --alter --topic demo --partitions 12

# ä¿®æ”¹å•ä¸ªtopicå­˜æ”¾æ•°æ®æ—¶é—´ï¼ˆå¦‚æœå•å¤©æ•°æ®é‡è¿‡å¤§ï¼Œå¯èƒ½éœ€è¦ä¸´æ—¶ä¿®æ”¹ï¼Œå•ä½msï¼‰
./bin/kafka-config.sh --zookeeper 192.168.202.131:2181 --entiy-type topics --entiy-name topic-xxxx --alter --add-config retention.ms=86400000

# groupç›¸å…³
# åˆ›å»ºgroupï¼ˆä¸€èˆ¬ä¸éœ€è¦æ‰‹åŠ¨åˆ›å»ºï¼‰
./bin/kafka-consumer-groups.sh --bootstrap-server 192.168.202.131:9092  --topic topic-xxx --consumer-property group.id=group_mytes

# æŸ¥çœ‹groupè¯¦æƒ…
./bin/kafka-consumer-groups.sh --bootstrap-server 192.168.202.131:9092  --group logstash-nginx --describe

# æŸ¥çœ‹groupåˆ—è¡¨
./bin/kafka-consumer-groups.sh --bootstrap-server 192.168.202.131:9092  --list

# åˆ é™¤group
./bin/kafka-consumer-groups.sh --bootstrap-server 192.168.202.131:9092  --group logstash-nginx --delete
```



### éªŒè¯å‘½ä»¤

```bash
# å¦‚æœELKæ•´ä½“æ­å»ºå®Œæ¯• å¹¶æ²¡æœ‰è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç´¢å¼• éœ€è¦æŒ‰é¡ºåºä¾æ¬¡ç¡®è®¤:
# 1. filebeat æ˜¯å¦æ”¶é›†åˆ°ç›¸å…³æ—¥å¿—
# 2. filebeat æ˜¯å¦è‡ªåŠ¨åˆ›å»º kafka topic
# 3. è‡ªåŠ¨åˆ›å»ºçš„ topic æ˜¯å¦å®é™…å­˜åœ¨æ¶ˆæ¯
# 4. logstash æ¶ˆè´¹ç»„ æ˜¯å¦æ¶ˆè´¹äº†æ¶ˆæ¯ï¼ˆoffsetã€lagï¼‰

# æŸ¥çœ‹ topic 
./bin/kafka-topics.sh --describe --topic NGINX-LOGS --bootstrap-server 192.168.202.131:9092
# è¾“å‡ºå†…å®¹ï¼ˆå±•ç¤ºäº†topicåˆ†åŒºå’Œå‰¯æœ¬çš„ç›¸å…³ä¿¡æ¯
Topic:NGINX-LOGS        PartitionCount:1        ReplicationFactor:1     Configs:segment.bytes=1073741824
        Topic: NGINX-LOGS       Partition: 0    Leader: 0       Replicas: 0     Isr: 0

# æŸ¥çœ‹æœ‰æ²¡æœ‰æ¶ˆæ¯ ä»ç¬¬ä¸€æ¡æ¶ˆæ¯å¼€å§‹æŸ¥çœ‹
./bin/kafka-console-consumer.sh --bootstrap-server 192.168.202.131:9092 --topic NGINX-LOGS --from-beginning
# è¾“å‡ºå†…å®¹ä¸º json æ ¼å¼çš„æ¶ˆæ¯

# æŸ¥çœ‹æ¶ˆè´¹è€…ç»„ æ¶ˆè´¹æƒ…å†µ
./bin/kafka-consumer-groups.sh --bootstrap-server 192.168.202.131:9092 --describe --group logstash-nginx
# è¾“å‡ºï¼ˆoffsetç›¸åŒåˆ™åˆ™æ¶ˆæ¯å‡è¢«æ¶ˆè´¹ LAGè¡¨ç¤ºè½åæœªè¢«æ¶ˆè´¹çš„æ¶ˆæ¯
TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST             CLIENT-ID
NGINX-LOGS      0          8               8               0               logstash-0-f0b8637b-26f6-4f23-ab80-f298f63aca6f /192.168.202.131 logstash-0
```








## Logstash

æµ‹è¯•éƒ¨ç½²æ¶ˆè´¹Kafkaæ—¥å¿—æ¶ˆæ¯ï¼Œæ¨é€åˆ°ESé›†ç¾¤çš„ Logstashï¼Œä½¿ç”¨ç‰ˆæœ¬ 7.5.1



### èµ„æºä¸‹è½½

å®˜æ–¹æ–‡æ¡£ï¼š[Installing Logstash | Logstash Reference [7.5] | Elastic](https://www.elastic.co/guide/en/logstash/7.5/installing-logstash.html)

ä¸‹è½½åœ°å€ï¼š[Logstash 7.5.1 | Elastic](https://www.elastic.co/cn/downloads/past-releases/logstash-7-5-1)



### éƒ¨ç½²

```bash
cd /app/
tar -zxvf logstash-7.5.1.tar.gz
mv logstash-7.5.1 logstash
cd logstash/config
mkdir pipeline
mv logstash.yml logstash.yml.bk
vim logstash.yml 
```

logstash.yml

```yaml
pipeline.workers: 5
pipeline.batch.size: 500
pipeline.batch.delay: 10
http.host: "0.0.0.0"
path.config: /app/logstash/config/pipeline    
config.reload.automatic: true
config.reload.interval: 60s
xpack.monitoring.enabled: true
xpack.monitoring.elasticsearch.username: logstash_system
xpack.monitoring.elasticsearch.password: "123456"
xpack.monitoring.elasticsearch.hosts: ["http://192.168.202.131:9200","http://192.168.202.131:9201","http://192.168.202.131:9202"]
```

ç»§ç»­åˆ›å»ºç®¡é“é…ç½®

```bash
vim pipeline/logstash.conf
```

logstash.conf

```markdown
input {
  kafka {
    bootstrap_servers => ["192.168.202.131:9092"]
    group_id => "logstash-nginx"
    auto_offset_reset => "latest"
    consumer_threads => 2
    topics => ["NGINX-LOGS"]
    codec => "json"
  }
}
filter {
  if [log][file][path] =~ /\/access-.*\.log$/ {
    grok {
      match => {"message" => "\[%{TIMESTAMP_ISO8601:logtime}\]"}
    }
    if [logtime] {
      date {
        match => [ "logtime", "ISO8601" ]
        timezone => "Asia/Shanghai"
      }
      mutate {
        gsub => ["logtime", "T[0-9]{2}:[0-9]{2}:[0-9]{2}\+[0-9]{2}:[0-9]{2}", ""]
        gsub => ["logtime", "[-]", "."]
        copy => {"[log][file][path]" => "logpath"}
        remove_field => ["input", "host", "agent", "ecs", "topic", "@version", "log"]
      }
      fingerprint {
        source => ["remote_ip", "logpath", "message"]
        target => "[@metadata][fingerprint]"
        method => "MD5"
        key => "Log Deduplicate"
        base64encode => true
        concatenate_sources => true
      }
    } else {
      drop {}
    }
  } else if [log][file][path] =~ /\/error\.log$/ {
    grok {
      pattern_definitions => { "ERROR_TIME" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME}" }
      match => {"message" => "%{ERROR_TIME:logtime}"}
    }
    if [logtime] {
      date {
        match => [ "logtime", "yyyy/MM/dd HH:mm:ss" ]
        timezone => "Asia/Shanghai"
      }
      mutate {
        gsub => ["logtime", " [0-9]{2}:[0-9]{2}:[0-9]{2}", ""]
        gsub => ["logtime", "[/]", "."]
        copy => {"[log][file][path]" => "logpath"}
        remove_field => ["input", "host", "agent", "ecs", "topic", "@version", "log"]
      }
      fingerprint {
        source => ["remote_ip", "logpath", "message"]
        target => "[@metadata][fingerprint]"
        method => "MD5"
        key => "Log Deduplicate"
        base64encode => true
        concatenate_sources => true
      }
    } else {
      drop {}
    }
  } else {
    drop {}
  }
}
output {
  elasticsearch {
    hosts => ["http://192.168.202.131:9200","http://192.168.202.131:9201","http://192.168.202.131:9202"]
    document_id => "%{[@metadata][fingerprint]}"
    index => "applogs-%{system}-%{logtime}"
    template_name => "applogs"
    user => "logstash_writer"
    password => "123456"
  }
}
```

åˆ›å»ºå¯åœè„šæœ¬

```bash
cd /app/logstash/bin
vim start.sh
vim stop.sh
```

start.sh

```shell
nohup /app/logstash/bin/logstash 2>&1 &
```

stop.sh

```shell
pid=`ps -ef | grep logstash | awk '{print $2}'`
kill -15 $pid
```

å¯åŠ¨

```bash
sh start.sh
```

æ£€æŸ¥æ—¥å¿—

```bash
cd /app/logstash/logs
```

## ElasticSearch

æµ‹è¯•éƒ¨ç½²æ”¶é›†æ—¥å¿—çš„æ–‡æ¡£æ•°æ®åº“ï¼Œä½¿ç”¨å•æœºå¤šè¿›ç¨‹çš„æ–¹å¼ï¼Œæ¨¡æ‹Ÿ3èŠ‚ç‚¹ESé›†ç¾¤

æ¨¡æ‹ŸèŠ‚ç‚¹ä¿¡æ¯å’Œè§’è‰²è§„åˆ’å¦‚ä¸‹

| èŠ‚ç‚¹      | IP              | ç«¯å£       | ä¸»èŠ‚ç‚¹ | æ•°æ®èŠ‚ç‚¹ |
| --------- | --------------- | ---------- | ------ | -------- |
| æ¨¡æ‹ŸèŠ‚ç‚¹1 | 192.168.202.131 | 9200ï¼Œ9300 | TRUE   | FALSE    |
| æ¨¡æ‹ŸèŠ‚ç‚¹2 | 192.168.202.131 | 9201ï¼Œ9301 | TRUE   | TRUE     |
| æ¨¡æ‹ŸèŠ‚ç‚¹3 | 192.168.202.131 | 9202ï¼Œ9302 | TRUE   | TRUE     |



**æ³¨æ„**ï¼š

ç”±äºæµ‹è¯•è™šæœºèµ„æºæœ‰é™ï¼Œè¿™é‡Œå°±ä¸åœ¨æ¨¡æ‹Ÿä»…æ˜¯åè°ƒè§’è‰²ï¼ˆnode.masterï¼šfalseï¼Œnode.dataï¼šfalseï¼‰çš„ESèŠ‚ç‚¹

ç”Ÿäº§ESé›†ç¾¤å»ºè®®ï¼Œ**ä¸»èŠ‚ç‚¹ã€åè°ƒèŠ‚ç‚¹ã€æ•°æ®èŠ‚ç‚¹ï¼Œå‡éœ€è¦å•ç‹¬æœºå™¨éƒ¨ç½²**



### èµ„æºä¸‹è½½

ä¸‹è½½åœ°å€ï¼š[Elasticsearch 7.5.1 | Elastic](https://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-5-1)

å®˜æ–¹æ–‡æ¡£ï¼š[Getting started with Elasticsearch | Elasticsearch Guide [7.5] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/getting-started.html)

é›†ç¾¤é…ç½®å‚æ•°ï¼š[Important discovery and cluster formation settings | Elasticsearch Guide [7.5] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/discovery-settings.html)

é…ç½®ä¸­gatewayå‚æ•°ï¼š[Local Gateway | Elasticsearch Guide [7.5] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/modules-gateway.html)



### éƒ¨ç½²

å‰ç½®æ“ä½œï¼ˆrootæ‰§è¡Œï¼‰

```markdown
# å…³é—­é˜²ç«å¢™
systemctl stop firewalld
systemctl disable firewalld

vim /etc/security/limits.conf 
# æ·»åŠ å¦‚ä¸‹å†…å®¹

* soft nofile 65536
* hard nofile 65536

* soft memlock unlimited
* hard memlock unlimited

# é€€å‡ºé‡æ–°ç™»å½•
# éªŒè¯
ulimit -Hn
ulimit -Sn

vim /etc/sysctl.conf
vm.max_map_count=655360
sudo sysctl -p

# å•æœºä¸‰ä¸ªå®‰è£…ç›®å½•æ¨¡æ‹Ÿä¸‰èŠ‚ç‚¹åˆ†åˆ«éƒ¨ç½²ES ï¼ˆmsè¡¨ç¤ºmasterï¼‰
tar -zxvf elasticsearch-7.5.1-linux-x86_64.tar.gz
mv elasticsearch-7.5.1 elasticsearch-ms1

tar -zxvf elasticsearch-7.5.1-linux-x86_64.tar.gz
mv elasticsearch-7.5.1 elasticsearch-ms2

tar -zxvf elasticsearch-7.5.1-linux-x86_64.tar.gz
mv elasticsearch-7.5.1 elasticsearch-ms3

# åˆ†åˆ«åˆ›å»ºå¯¹åº” æ—¥å¿—å’Œæ•°æ®ç›®å½•
mkdir -p /app/data/elasticsearch-ms1
mkdir -p /app/logs/elasticsearch-ms1

mkdir -p /app/data/elasticsearch-ms2
mkdir -p /app/logs/elasticsearch-ms2

mkdir -p /app/data/elasticsearch-ms3
mkdir -p /app/logs/elasticsearch-ms3

# å¢åŠ  es è¿è¡Œç”¨æˆ·
sudo adduser elasticsearch

sudo chown -R elasticsearch:elasticsearch /app/elasticsearch*

sudo chown -R elasticsearch:elasticsearch /app/data/elasticsearch*

sudo chown -R elasticsearch:elasticsearch /app/logs/elasticsearch*

su elasticsearch
```



#### éƒ¨ç½² æ¨¡æ‹ŸèŠ‚ç‚¹1

åˆ‡æ¢ç”¨æˆ·åï¼Œè¿›è¡Œé…ç½®è°ƒæ•´

```bash
cd /app/elasticsearch-ms1/config/
vim jvm.options
```

jvm.options

```properties
# æ¨¡æ‹ŸèŠ‚ç‚¹ è°ƒæ•´ä¸ºå°å †å†…å­˜
-Xms512m
-Xmx512m

## GC configuration

# ä¸ä½¿ç”¨CMSGC æ³¨é‡ŠCMSGC
#-XX:+UseConcMarkSweepGC
#-XX:CMSInitiatingOccupancyFraction=75
#-XX:+UseCMSInitiatingOccupancyOnly

## G1GC Configuration
# NOTE: G1GC is only supported on JDK version 10 or later.
# To use G1GC uncomment the lines below.
# 10-:-XX:-UseConcMarkSweepGC
# 10-:-XX:-UseCMSInitiatingOccupancyOnly
# æ”¾å¼€é»˜è®¤æ³¨é‡Š ä½¿ç”¨G1GCåƒåœ¾å›æ”¶ 
# å¯¹äºå¤§çš„å †å†…å­˜éœ€è¦ä½¿ç”¨G1GC
# ç”Ÿäº§ä¹Ÿæ˜¯å¦‚æ­¤
10-:-XX:+UseG1GC
10-:-XX:G1ReservePercent=25
10-:-XX:InitiatingHeapOccupancyPercent=30

# ä¸‹é¢çš„å‡ä¸ºé»˜è®¤é…ç½® ä¸ªäººåœ¨ä½¿ç”¨ä¸­æ²¡æœ‰åœ¨è¿›è¡Œè¿‡è°ƒæ•´

## JVM temporary directory
-Djava.io.tmpdir=${ES_TMPDIR}

## heap dumps

# generate a heap dump when an allocation from the Java heap fails
# heap dumps are created in the working directory of the JVM
-XX:+HeapDumpOnOutOfMemoryError

# specify an alternative path for heap dumps; ensure the directory exists and
# has sufficient space
-XX:HeapDumpPath=data

# specify an alternative path for JVM fatal error logs
-XX:ErrorFile=logs/hs_err_pid%p.log

## JDK 8 GC logging
8:-XX:+PrintGCDetails
8:-XX:+PrintGCDateStamps
8:-XX:+PrintTenuringDistribution
8:-XX:+PrintGCApplicationStoppedTime
8:-Xloggc:logs/gc.log
8:-XX:+UseGCLogFileRotation
8:-XX:NumberOfGCLogFiles=32
8:-XX:GCLogFileSize=64m

# JDK 9+ GC logging
9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m

```



åˆ›å»ºESé›†ç¾¤ä¼ è¾“åŠ å¯†è¯ä¹¦

```markdown
cd /app/elasticsearch-ms1
# åˆ›å»ºCAè¯ä¹¦
/app/elasticsearch-ms1/bin/elasticsearch-certutil ca --days 99999
# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
openssl pkcs12 -in elastic-stack-ca.p12 -nodes | openssl x509 -noout -enddate

# åˆ›å»ºç§é’¥è¯ä¹¦
/app/elasticsearch-ms1/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --days 99999

# å¤åˆ¶è¯ä¹¦åˆ° ms2 ms3
cd /app/elasticsearch-ms2/config
cp /app/elasticsearch-ms1/config/elastic-* .

cd /app/elasticsearch-ms3/config
cp /app/elasticsearch-ms1/config/elastic-* .
```



è°ƒæ•´ ES é…ç½®

```bash
vim elasticsearch.yml
```

elasticsearch.yml

```yaml
# å•æœºæ¨¡æ‹Ÿéƒ¨ç½²éœ€è¦é…ç½® è¿è¡Œä¸€å°æœºå™¨è¿è¡Œå¤šä¸ªESè¿›ç¨‹
node.max_local_storage_nodes: 3

# æŒ‡å®šé›†ç¾¤åç§°
cluster.name: es-cluster
# æŒ‡å®šèŠ‚ç‚¹åç§°
node.name: ms1
# æ•°æ®ç›®å½•
path.data: /app/data/elasticsearch-ms1
# æ—¥å¿—ç›®å½•
path.logs: /app/logs/elasticsearch-ms1
network.host: 0.0.0.0
http.port: 9200

# é›†ç¾¤å‘ç°
# è®¾ç½®æ‰€æœ‰ä¸»èŠ‚ç‚¹IP
discovery.seed_hosts: ["192.168.202.131:9300","192.168.202.131:9301","192.168.202.131:9302"]
# Masterè§’è‰²çš„èŠ‚ç‚¹ node.name çš„åç§°  
cluster.initial_master_nodes: ["ms1","ms2","ms3"]

bootstrap.memory_lock: true

# ç½‘å…³ä¿¡æ¯ éœ€è¦æ ¹æ®å®é™…çš„ ESé›†ç¾¤è§„åˆ’ è¿›è¡Œè°ƒæ•´
# åˆæ¬¡éƒ¨ç½² ä¸æ»¡è¶³ç›¸å…³ expected é›†ç¾¤çŠ¶æ€åˆ™ä¸º RAD
# æœŸæœ›ä¸»èŠ‚ç‚¹æ•°
gateway.expected_master_nodes: 3
# æœŸæœ›æ•°æ®èŠ‚ç‚¹æ•°
gateway.expected_data_nodes: 2
gateway.recover_after_time: 5m
# é›†ç¾¤æ¢å¤æ‰€éœ€ æœ€å°‘ master èŠ‚ç‚¹
gateway.recover_after_master_nodes: 2
# é›†ç¾¤æ¢å¤æ‰€éœ€ æœ€å°‘ data èŠ‚ç‚¹
gateway.recover_after_data_nodes: 1

bootstrap.system_call_filter: false
http.cors.enabled: true
http.cors.allow-origin: "*"
http.max_content_length: 100mb

#tcpç«¯å£
transport.tcp.port: 9300
transport.tcp.compress: true

# å½“ node.master: true node.data: false æ˜¯å½“å‰èŠ‚ç‚¹ä»…ä¸ºä¸»èŠ‚ç‚¹
# å½“ node.master: false node.data: true æ˜¯å½“å‰èŠ‚ç‚¹ä»…ä¸ºæ•°æ®èŠ‚ç‚¹
# å½“ node.master: false node.data: false æ˜¯å½“å‰èŠ‚ç‚¹ä»…ä¸ºåè°ƒèŠ‚ç‚¹

# ç”Ÿäº§ç¯å¢ƒä¸­ç»å¯¹ä¸èƒ½ä½¿masterä¹Ÿå¯ä»¥ä½œä¸ºæ•°æ®èŠ‚ç‚¹ 
# å½“ node.master: true node.data: true æ˜¯å½“å‰èŠ‚ç‚¹ä¸ºä¸»èŠ‚ç‚¹å’Œæ•°æ®èŠ‚ç‚¹

#å£°æ˜æ˜¯masterèŠ‚ç‚¹
node.master: true
#å£°æ˜æ˜¯æ•°æ®èŠ‚ç‚¹
node.data: false

# é›†ç¾¤åŠ å¯†ä¼ è¾“
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: /app/elasticsearch-ms1/config/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: /app/elasticsearch-ms1/config/elastic-certificates.p12

thread_pool.write.queue_size: 5000

#ç¼“å­˜æ¸…ç†é…ç½®
indices.fielddata.cache.size: 30%
```



åˆ›å»ºå¯åŠ¨è„šæœ¬

```bash
cd /app/elasticsearch-ms1/config/
vim start.sh
vim stop.sh
```

start.sh

```shell
/app/elasticsearch-ms1/bin/elasticsearch  -d
```

stop.sh

```shell
jps | grep Elasticsearch | awk '{print $1}' | xargs kill -15
```



å¯åŠ¨ ES æ¨¡æ‹ŸèŠ‚ç‚¹1

```bash
sh start.sh
```



#### éƒ¨ç½² æ¨¡æ‹ŸèŠ‚ç‚¹2

å‚è€ƒéƒ¨ç½²æ¨¡æ‹ŸèŠ‚ç‚¹1ï¼Œä¸‹é¢ä»…é™„ç›¸å…³confé…ç½®

jvm.options ä¸ æ¨¡æ‹ŸèŠ‚ç‚¹1 ç›¸åŒ

elasticsearch.yml

```yaml
node.max_local_storage_nodes: 3

cluster.name: es-cluster
node.name: ms2

path.data: /app/data/elasticsearch-ms2
path.logs: /app/logs/elasticsearch-ms2
network.host: 0.0.0.0
http.port: 9201

discovery.seed_hosts: ["192.168.202.131:9300","192.168.202.131:9301","192.168.202.131:9302"]
cluster.initial_master_nodes: ["ms1","ms2","ms3"]

bootstrap.memory_lock: true

gateway.expected_master_nodes: 3
gateway.expected_data_nodes: 2
gateway.recover_after_time: 5m
gateway.recover_after_master_nodes: 2
gateway.recover_after_data_nodes: 1

bootstrap.system_call_filter: false
http.cors.enabled: true
http.cors.allow-origin: "*"
http.max_content_length: 100mb

transport.tcp.port: 9301
transport.tcp.compress: true

node.master: true
node.data: true

xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: /app/elasticsearch-ms2/config/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: /app/elasticsearch-ms2/config/elastic-certificates.p12

thread_pool.write.queue_size: 5000

indices.fielddata.cache.size: 30%
```



#### éƒ¨ç½² æ¨¡æ‹ŸèŠ‚ç‚¹3

å‚è€ƒéƒ¨ç½²æ¨¡æ‹ŸèŠ‚ç‚¹1ï¼Œä¸‹é¢ä»…é™„ç›¸å…³confé…ç½®

jvm.options ä¸ æ¨¡æ‹ŸèŠ‚ç‚¹1 ç›¸æ¯” ä»…å †å†…å­˜è®¾ç½®ä¸åŒ

```properties
-Xms1g
-Xmx1g
```

elasticsearch.yml

```yaml
node.max_local_storage_nodes: 3

cluster.name: es-cluster
node.name: ms3

path.data: /app/data/elasticsearch-ms3
path.logs: /app/logs/elasticsearch-ms3
network.host: 0.0.0.0
http.port: 9202

discovery.seed_hosts: ["192.168.202.131:9300","192.168.202.131:9301","192.168.202.131:9302"]
cluster.initial_master_nodes: ["ms1","ms2","ms3"]

bootstrap.memory_lock: true

gateway.expected_master_nodes: 3
gateway.expected_data_nodes: 2
gateway.recover_after_time: 5m
gateway.recover_after_master_nodes: 2
gateway.recover_after_data_nodes: 1

bootstrap.system_call_filter: false
http.cors.enabled: true
http.cors.allow-origin: "*"
http.max_content_length: 100mb

transport.tcp.port: 9302
transport.tcp.compress: true

node.master: true
node.data: true

xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: /app/elasticsearch-ms3/config/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: /app/elasticsearch-ms3/config/elastic-certificates.p12

thread_pool.write.queue_size: 5000
indices.fielddata.cache.size: 30%
```



#### ä¿®æ”¹ç”¨æˆ·å¯†ç 

**ä¸‰å°æ¨¡æ‹ŸèŠ‚ç‚¹å®Œå…¨å¯åŠ¨å**ï¼Œä¿®æ”¹æ‰€æœ‰ ES ç”¨æˆ·å¯†ç 

æ­¤æ—¶å¦‚æœé›†ç¾¤å¼‚å¸¸ï¼Œä¼šæœ‰RADçŠ¶æ€æç¤ºï¼Œè¿™æ—¶æ˜¯æ— æ³•è¿›è¡Œæ“ä½œä¿®æ”¹å¯†ç çš„

```markdown
cd /app/elasticsearch-ms1
bin/elasticsearch-setup-passwords interactive
# æŒ‰ç”¨æˆ·ä¾æ¬¡è¾“å…¥å¯†ç 
# æµ‹è¯•å»ºè®®ä¿æŒä¸€è‡´ 123456 å³ é‡ç½®æ‰€æœ‰ç”¨æˆ·å¯†ç ä¸º 123456
```



#### è¡¥å……å†…å®¹

ES å¯¹å †å†…å­˜çš„è¦æ±‚æ¯”è¾ƒé“­æ„Ÿ

æ‰€æœ‰è§’è‰²çš„ESèŠ‚ç‚¹å †å†…å­˜è®¾ç½® **ä¸èƒ½è¶…è¿‡è™šæ‹Ÿæœºçš„å®é™…å†…å­˜çš„ä¸€åŠä¸”ä¸èƒ½è¶…è¿‡ 30G**

æˆ‘åœ¨å®é™…ç”Ÿäº§ä½¿ç”¨ä¸­  

ä¸»èŠ‚ç‚¹å’Œåè°ƒèŠ‚ç‚¹ ä¸º 16C 32G æœåŠ¡å™¨ æ‰€ä»¥å †å†…å­˜è®¾ç½®ä¸º 16G

æ•°æ®èŠ‚ç‚¹ä¸º 32C 64G æœåŠ¡å™¨ æ‰€ä»¥å †å†…å­˜è®¾ç½®ä¸º 30G

é™„ä¸€ä»½ ç”Ÿäº§ ES master è§’è‰² jvm.options é…ç½®ï¼ˆä»…ä¾›å‚è€ƒ

jvm.option

```properties
## JVM configuration

################################################################
## IMPORTANT: JVM heap size
################################################################
##
## You should always set the min and max JVM heap
## size to the same value. For example, to set
## the heap to 4 GB, set:
##
## -Xms4g
## -Xmx4g
##
## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html
## for more information
##
################################################################

# Xms represents the initial size of total heap space
# Xmx represents the maximum size of total heap space

-Xms16g
-Xmx16g

################################################################
## Expert settings
################################################################
##
## All settings below this section are considered
## expert settings. Don't tamper with them unless
## you understand what you are doing
##
################################################################

## GC configuration
#-XX:+UseConcMarkSweepGC
#-XX:CMSInitiatingOccupancyFraction=75
#-XX:+UseCMSInitiatingOccupancyOnly

## G1GC Configuration
# NOTE: G1GC is only supported on JDK version 10 or later.
# To use G1GC uncomment the lines below.
# 10-:-XX:-UseConcMarkSweepGC
# 10-:-XX:-UseCMSInitiatingOccupancyOnly
10-:-XX:+UseG1GC
10-:-XX:G1ReservePercent=25
10-:-XX:InitiatingHeapOccupancyPercent=30

## JVM temporary directory
-Djava.io.tmpdir=${ES_TMPDIR}

## heap dumps

# generate a heap dump when an allocation from the Java heap fails
# heap dumps are created in the working directory of the JVM
-XX:+HeapDumpOnOutOfMemoryError

# specify an alternative path for heap dumps; ensure the directory exists and
# has sufficient space
-XX:HeapDumpPath=data

# specify an alternative path for JVM fatal error logs
-XX:ErrorFile=logs/hs_err_pid%p.log

## JDK 8 GC logging
8:-XX:+PrintGCDetails
8:-XX:+PrintGCDateStamps
8:-XX:+PrintTenuringDistribution
8:-XX:+PrintGCApplicationStoppedTime
8:-Xloggc:logs/gc.log
8:-XX:+UseGCLogFileRotation
8:-XX:NumberOfGCLogFiles=32
8:-XX:GCLogFileSize=64m

# JDK 9+ GC logging
9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m
```



é™„ä¸€ä»½  ES master èŠ‚ç‚¹é…ç½®ï¼ˆä»…ä¾›å‚è€ƒ

elasticsearch.yml

```yaml
#æŒ‡å®šé›†ç¾¤åç§°
cluster.name: xxx-cluster
#æŒ‡å®šèŠ‚ç‚¹åç§°
node.name: xxx01
#æ•°æ®ç›®å½•
path.data: /app/data
path.logs: /app/logs
network.host: 0.0.0.0
http.port: 9200
#é›†ç¾¤å‘ç°
discovery.seed_hosts: ["1.1.1.1","1.1.1.2","1.1.1.3"]
#è®¾ç½®ç¬¦åˆä¸»èŠ‚ç‚¹çš„ä¸»æœºåï¼Œå¼•å¯¼å¯åŠ¨é›†ç¾¤
cluster.initial_master_nodes: ["xxx01","xxx02","xxx03"]

bootstrap.memory_lock: true

#ç½‘å…³ä¿¡æ¯
gateway.expected_master_nodes: 2
gateway.expected_data_nodes: 3
gateway.recover_after_time: 5m
gateway.recover_after_master_nodes: 2
gateway.recover_after_data_nodes: 3

bootstrap.system_call_filter: false
http.cors.enabled: true
http.cors.allow-origin: "*"
http.max_content_length: 100mb
#tcpç«¯å£
transport.tcp.port: 9300
transport.tcp.compress: true
#å£°æ˜æ˜¯ master èŠ‚ç‚¹
node.master: true
#å£°æ˜æ˜¯ data èŠ‚ç‚¹
node.data: false
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: /app/elasticsearch/config/cert/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: /app/elasticsearch/config/cert/elastic-certificates.p12

thread_pool.write.queue_size: 5000

path.repo: ["/app/elasticsearch/repository3/snapshot","/app/elasticsearch/repository5/snapshot","/app/elasticsearch/repository/snapshot"]

#ç¼“å­˜æ¸…ç†é…ç½®
indices.fielddata.cache.size: 30%
```



### é›†ç¾¤è¿ç»´

è§ Kibana éƒ¨åˆ†çš„ å¸¸è§é›†ç¾¤ç®¡ç†åœºæ™¯



### å¯¹è±¡å­˜å‚¨

#### åˆ›å»ºMinio ä»“åº“

```markdown
# TLS å¯é€‰
# é…ç½®è‡ªç­¾è¯ä¹¦ es æ— æ³•éªŒè¯å­˜å‚¨åº“
# PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target

mkdir -p ${HOME}/.minio/certs
cd ${HOME}/.minio/certs

openssl req -x509 -newkey rsa:4096 -days 365 -nodes -keyout ca-key.pem -out ca-cert.pem -subj "/C=CN/ST=Shanghai/L=Shanghai/O=Education/OU=Education/CN=*.ca.com/emailAddress=test@email.com"

openssl req -newkey rsa:4096 -nodes -keyout private.key -out csr.pem -subj "/C=CN/ST=Shanghai/L=Shanghai/O=TEST1/OU=TEST2/CN=*.server.com/emailAddress=test@email.com"

cat > ./server-ext.cnf << EOF
subjectAltName=DNS:test.minio.com
EOF

openssl x509 -req -in csr.pem -days 3650 -CA ca-cert.pem -CAkey ca-key.pem -CAcreateserial -out public.crt -extfile server-ext.cnf

cat >> /etc/hosts << EOF
192.168.202.131   test.minio.com
EOF

# Minio æµ‹è¯•å•èŠ‚ç‚¹éƒ¨ç½²
mkdir -p /app/data/minio
mkdir -p /app/minio
cd /app/minio
wget https://dl.min.io/server/minio/release/linux-amd64/archive/minio.RELEASE.2023-10-14T05-17-22Z
mv minio.RELEASE.2023-10-14T05-17-22Z minio
chmod +x minio
nohup /app/minio/minio server /app/data/minio --console-address ":9001"  2>&1 &

# æµ‹è¯•ä½¿ç”¨é»˜è®¤minioè´¦å·å¯†ç 
minioadmin / minioadmin

# mc åˆ›å»ºæ¡¶ ç­–ç•¥ ç”¨æˆ·
# https://min.io/docs/minio/linux/reference/minio-mc.html
cd /app/minio
wget https://dl.min.io/client/mc/release/linux-amd64/archive/mc.RELEASE.2023-10-14T01-57-03Z
mv mc.RELEASE.2023-10-14T01-57-03Z mc

cat >/tmp/es-rw.json << EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:*"
            ],
            "Resource": [
                "arn:aws:s3:::es-s3/*"
            ]
        }
    ]
}
EOF

./mc alias set minio http://192.168.202.131:9000
./mc mb minio/es-s3
./mc admin policy create minio es-rw /tmp/es-rw.json
./mc admin user add minio esuser
esuser / esuseradmin
./mc admin policy attach minio es-rw --user esuser
./mc admin user svcacct add minio esuser

# è·å–æµ‹è¯•å¯†é’¥
Access Key: 6AAB05L0AHCP1YT4UM0Z
Secret Key: WriVttuEUvHtx5V7gbQo+wpUeP3sJeiUUNq0ga4a
Expiration: no-expiry
```



#### åˆ›å»ºES S3ä»“åº“

[ä¸‹è½½å¯¹è±¡å­˜å‚¨æ’ä»¶](https://artifacts.elastic.co/downloads/elasticsearch-plugins/repository-s3/repository-s3-7.5.2.zip)

[å®˜æ–¹S3ä»“åº“æ’ä»¶æ–‡æ¡£](https://www.elastic.co/guide/en/elasticsearch/plugins/7.17/repository-s3-client.html)

ä¸Šä¼ æ’ä»¶å‹ç¼©åŒ…åˆ°æ‰€æœ‰esèŠ‚ç‚¹ /tmp ç›®å½•ä¸‹ï¼Œæ’ä»¶åŒ…åç§° repository-s3-7.5.1.zip

åœ¨æ‰€æœ‰esèŠ‚ç‚¹ä¸Šå®‰è£…æ’ä»¶åŒ…

```shell
# æŸ¥çœ‹å·²ç»å®‰è£…æ’ä»¶åŒ…
/app/elasticsearch-ms1/bin/elasticsearch-plugin list 

# å®‰è£…s3å­˜å‚¨æ’ä»¶åŒ…
/app/elasticsearch-ms1/bin/elasticsearch-plugin install file:///tmp/repository-s3-7.5.1.zip

# æŸ¥çœ‹æ˜¯å¦å·²ç»å®‰è£…
/app/elasticsearch-ms1/bin/elasticsearch-plugin list 
```

åœ¨èŠ‚ç‚¹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå…³é—­ç´¢å¼•è‡ªåŠ¨è¿ç§»

```shell
# ç¦ç”¨åˆ†ç‰‡è‡ªåŠ¨åˆ†é…
PUT _cluster/settings
{
"persistent": {
  "cluster.routing.allocation.enable": "none"
}
}
  
# æ‰§è¡ŒåŒæ­¥åˆ·æ–°å¯åŠ å¿«åˆ†ç‰‡å¿«é€Ÿæ¢å¤
POST _flush/synced
```

æ»šåŠ¨é‡å¯æ‰€æœ‰esèŠ‚ç‚¹ï¼ˆé‡å¯é¡ºåº data core masterï¼‰

```Shell
cd /app/elasticsearch-ms1/bin/
# åœæ­¢
./stop.sh

# æŸ¥çœ‹æ˜¯å¦å®Œå…¨åœæ­¢
ps -ef | grep elasticsearch

# å¯åŠ¨
./start.sh

# kibanaæŸ¥çœ‹é›†ç¾¤èŠ‚ç‚¹æ˜¯å¦æ­£å¸¸
GET _cat/node
# kibanaæŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶æ€
GET _cat/health
```

å¼€å¯æ‰€æœ‰åˆ†ç‰‡è‡ªåŠ¨åˆ†é…

```Shell
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.enable": "all"
  }
}
```

æµ‹è¯•ç½‘ç»œè”é€šæ€§

```Shell
ping s3.test.com
telnet s3.test.com 443
```

å¢åŠ è®¤è¯

```markdown
# æ‰€æœ‰èŠ‚ç‚¹å¢åŠ é»˜è®¤ client å¯†é’¥
/app/elasticsearch-ms1/bin/elasticsearch-keystore add s3.client.default.access_key
/app/elasticsearch-ms1/bin/elasticsearch-keystore add s3.client.default.secret_key

/app/elasticsearch-ms2/bin/elasticsearch-keystore add s3.client.default.access_key
/app/elasticsearch-ms2/bin/elasticsearch-keystore add s3.client.default.secret_key

/app/elasticsearch-ms3/bin/elasticsearch-keystore add s3.client.default.access_key
/app/elasticsearch-ms3/bin/elasticsearch-keystore add s3.client.default.secret_key
```



kibanaæ·»åŠ å¯¹è±¡å­˜å‚¨é…ç½®

```shell
# é‡è½½é»˜è®¤å¯†é’¥
POST _nodes/reload_secure_settings

# 7.5.1 æ­£ç¡®çš„å½¢å¼
PUT _snapshot/s3_repository
{
  "type": "s3",
  "settings": {
    "bucket": "es-s3",
    "endpoint": "test.minio.com:9000",
    "path_style_access": true,
    "protocol": "http",
    "max_restore_bytes_per_sec": "50mb",
    "max_snapshot_bytes_per_sec": "50mb"
  }
}

# ä¸æ”¯æŒçš„å½¢å¼
PUT _snapshot/my_s3_repository
{
  "type": "s3",
  "settings": {
    "bucket": "es-s3",
    "client": "test",
    "access_key": "6AAB05L0AHCP1YT4UM0Z",
    "secret_key": "WriVttuEUvHtx5V7gbQo+wpUeP3sJeiUUNq0ga4a",
    "endpoint": "http://192.168.202.131:9000"
  }
}
```

kibanaæŸ¥çœ‹å­˜å‚¨åº“æ˜¯å¦åˆ›å»ºæˆåŠŸ

```shell
GET /_snapshot/_all
GET _cat/repositories
GET _snapshot/s3_repository
```

å¦‚æœéœ€è¦åˆ é™¤

åˆ é™¤å­˜å‚¨åº“

```Shell
DELETE _snapshot/s3_repository
```

åˆ é™¤s3æ’ä»¶

```Shell
./elasticsearch-plugin remove repository-s3
```



æµ‹è¯•å¤‡ä»½

```shell
# å¤‡ä»½äº†å½“å‰æ‰€æœ‰ç´¢å¼•
PUT _snapshot/s3_repository/snapshot_test?wait_for_completion=true
GET _snapshot/s3_repository/_all
```

è„šæœ¬å¤‡ä»½

```shell
cat > /tmp/snapshot_tmp.json << EOF
{
  "indices": "applogs-test-2024.05.21,applogs-test-2024.05.24",
  "ignore_unavailable": true,
  "include_global_state": false
}
EOF

curl -s -u elastic:123456 -X PUT -H "Content-type: application/json" -d @/tmp/snapshot_tmp.json "http://127.0.0.1:9200/_snapshot/s3_repository/snapshot_test3?wait_for_completion=true&pretty"
```

æ‰§è¡Œç»“æœ

```bash
[elasticsearch@test /]$ curl -s -u elastic:123456 -X PUT -H "Content-type: application/json" -d @/tmp/snapshot_tmp.json "http://127.0.0.1:9200/_snapshot/s3_repository/snapshot_test3?wait_for_completion=true&pretty"
{
  "snapshot" : {
    "snapshot" : "snapshot_test3",
    "uuid" : "pbBLKw-ARra3DubsGtcfuw",
    "version_id" : 7050199,
    "version" : "7.5.1",
    "indices" : [
      "applogs-test-2024.05.21",
      "applogs-test-2024.05.24"
    ],
    "include_global_state" : false,
    "state" : "SUCCESS",
    "start_time" : "2024-07-23T06:43:19.558Z",
    "start_time_in_millis" : 1721716999558,
    "end_time" : "2024-07-23T06:43:19.961Z",
    "end_time_in_millis" : 1721716999961,
    "duration_in_millis" : 403,
    "failures" : [ ],
    "shards" : {
      "total" : 3,
      "failed" : 0,
      "successful" : 3
    }
  }
}
```

## Kibana

æµ‹è¯•éƒ¨ç½²Kibanaï¼Œç‰ˆæœ¬å’ŒESä¿æŒä¸€è‡´ 7.5.1



### èµ„æºä¸‹è½½

ä¸‹è½½åœ°å€ï¼š[Kibana 7.5.1 | Elastic](https://www.elastic.co/cn/downloads/past-releases/kibana-7-5-1)



### éƒ¨ç½²

root ç”¨æˆ·å‡†å¤‡ç›®å½•

```bash
cd /app
tat -zxvf kibana-7.5.1-linux-x86_64.tar.gz
mv kibana-7.5.1-linux-x86_64 kibana
mkdir -p /app/logs/kibana
sudo chown -R elasticsearch:elasticsearch /app/logs/kibana
sudo chown -R elasticsearch:elasticsearch /app/kibana
su elasticsearch
```

åˆ‡æ¢ elasticsearch ç”¨æˆ·å è¿›è¡Œé…ç½®ç¼–è¾‘å’Œå¯åŠ¨

```bash
cd /app/kibana/config
cp kibana.yml kibana.yml.bk
vim kibana.yml
```

kibana.yml

```yaml
# æ¨èçš„è°ƒæ•´çš„é…ç½®å¦‚ä¸‹ å¹¶åˆ é™¤äº†å¤šä½™æ³¨é‡Š
# å…¶ä»–é…ç½®é¡¹å’Œæ‰€æœ‰é…ç½®çš„å…·ä½“å«ä¹‰å‚è€ƒ kibana.yml.bk ä¸­çš„è‹±æ–‡æ³¨é‡Š
server.port: 5601
server.host: "0.0.0.0"
server.basePath: "/kibana"
server.rewriteBasePath: true
server.maxPayloadBytes: 1048576
# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ è¿™é‡Œæ¨èé…ç½® ES é›†ç¾¤çš„åè°ƒèŠ‚ç‚¹ 
# åè°ƒèŠ‚ç‚¹å³ elasticsearch.yml node.master node.data å‡è®¾ç½®ä¸º false çš„èŠ‚ç‚¹
elasticsearch.hosts: ["http://192.168.202.131:9200","http://192.168.202.131:9201","http://192.168.202.131:9202"]
elasticsearch.username: "kibana"
elasticsearch.password: "123456"
elasticsearch.logQueries: true
logging.dest: /app/logs/kibana/kibana.log
logging.verbose: true
i18n.locale: "zh-CN"

# æœ‰æ—¶å€™ kibana åœ¨æŸ¥è¯¢å¯¹è±¡å­˜å‚¨åº“æ—¶ä¼š504è¶…æ—¶ è°ƒæ•´å‰ç«¯è¶…æ—¶å‚æ•°
elasticsearch.requestTimeout: 90000
```

ç¼–è¾‘å¯åŠ¨è„šæœ¬

```bash
cd /app/kibana/bin
vim kibana
```

kibana é»˜è®¤å¯åŠ¨è„šæœ¬æœ€åæ·»åŠ nodeå‚æ•°  --max-old-space-size=4096

å¦‚æœä¸è°ƒæ•´ kibana node å‚æ•° å¯èƒ½åœ¨å¤§æ•°æ®é‡çš„æŸ¥è¯¢ä¸‹é€ æˆå´©æºƒ

```shell
NODE_OPTIONS="--no-warnings --max-http-header-size=65536 --max-old-space-size=4096 ${NODE_OPTIONS}" NODE_ENV=production exec "${NODE}" "${DIR}/src/cli" ${@}
```

å¢åŠ å¯åœè„šæœ¬

```bash
vim start.sh
vim stop.sh
```

start.sh

```shell
nohup /app/kibana/bin/kibana 2>&1 &
```

stop.sh

```shell
pid=`ps -ef | grep kibana | grep node | awk '{print $2}'`
kill -15 $pid
```

å¯åŠ¨kibana

```bash
sh start.sh
```



### ç™»å½•

è®¿é—®ï¼šhttp://192.168.202.131:5601/kibana/login

ç”¨æˆ·ï¼šelastic

å¯†ç ï¼šxxxxx

è´¦å·å¯†ç åœ¨éƒ¨ç½²å®ŒæˆESé›†ç¾¤åéœ€è¦è‡ªè¡Œé‡ç½®ï¼Œæ¨èè®¾ç½®æˆç›¸åŒå¯†ç ï¼Œå‚è€ƒESç« èŠ‚çš„å†…å®¹



### è§’è‰²ç®¡ç†

å»ºè®®ç»™logstash åˆ›å»ºå•ç‹¬ç”¨æˆ·å’Œè§’è‰² logstash_writer 

è§’è‰²è®¾ç½®å‚è€ƒå¦‚ä¸‹

![image-20240723151200650](https://image.lkarrie.com/images/2024/10/22/kibana-user1.png)



é€šå¸¸åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿˜ä¼šç»™å…¶ä»–ä½¿ç”¨è€…åˆ›å»ºåªè¯»è´¦å·

å¦‚æœæƒ³è®¾ç½®ç´¢å¼•çš„åªè¯»ç”¨æˆ·ï¼Œåªè¯»ç”¨æˆ·çš„è§’è‰²é›†ç¾¤æƒé™æ— éœ€èµ‹äºˆï¼Œåªé…ç½®è§’è‰²éœ€å…³æ³¨çš„ç´¢å¼•å’Œå¢åŠ ç´¢å¼•æƒé™ read, view_index_metadata, monitor å³å¯ 



### Kibanaé«˜çº§è®¾ç½®

æ¨èå¯¹ Kibana ä¸­çš„é«˜çº§è®¾ç½®åšå‡ºå¦‚ä¸‹çš„è°ƒæ•´

ç®¡ç† > é«˜çº§è®¾ç½®

#### Date format

* è°ƒæ•´ä¸º	YYYY-MM-DD HH:mm:ss.SSS

![kibana-setting-1.png](https://image.lkarrie.com/images/2024/10/22/kibana-setting-1.png)

#### Meta fields

* è°ƒæ•´ä¸º	_source, _index

![kibana-setting-2](https://image.lkarrie.com/images/2024/10/22/kibana-setting-2.png)

#### Default columns

* è°ƒæ•´ä¸º	message

![kibana-setting-3](https://image.lkarrie.com/images/2024/10/22/kibana-setting-3.png)

è¿™äº›è®¾ç½®ï¼Œä¸»è¦æ˜¯æœåŠ¡ç”¨æˆ·ï¼Œè®© Discover æ›´ä¸ºä¼˜é›…

* è¿›å…¥ Discover  åé»˜è®¤å±•ç¤º message å­—æ®µï¼ˆå®é™…æ—¥å¿—å†…å®¹ï¼‰è€Œä¸æ˜¯ _source 
* ä½¿ Time åˆ— æ—¶é—´ æ›´åŠ å¯è¯»
* éšè—ä¸€äº›æ— éœ€å‚åŠ ç­›é€‰çš„é»˜è®¤å†…ç½®å­—æ®µï¼ˆä¾‹å¦‚ _typeï¼‰

![kibana-discover](https://image.lkarrie.com/images/2024/10/22/kibana-discover.png)



### ES Stackç›‘æ§

ä½¿ç”¨å†…éƒ¨æ•°ç›‘æ§ï¼ˆxpack.monitoring.collection.enabled: trueï¼‰å³å¯ï¼Œå¯ä»¥ä¸éœ€è¦å®‰è£… Metricbeatï¼Œç›´æ¥å¼€kibanaé¡µé¢ä¸­å¯ç”¨

Stack ç›‘æ§ > 

ç‚¹å‡»ä½¿ç”¨å†…éƒ¨æ•°æ®ç›‘æ§ï¼Œç­‰å¾…åˆå§‹åŒ–å‡ ç§’å³å¯

![kibana-monitoring-1](https://image.lkarrie.com/images/2024/10/22/kibana-monitoring-1.png)



Stack ç›‘æ§ > Elasticsearch æ¦‚è§ˆ 

å¯ä»¥æŸ¥çœ‹ ES é›†ç¾¤çš„ä¸€äº›åŸºç¡€ç›‘æ§æ•°æ®



å¸¸ç”¨ æ¦‚è§ˆä¸‹çš„ åˆ†ç‰‡æ´»åŠ¨ è§‚å¯Ÿ ES çš„åˆ†ç‰‡è¿ç§»è¿›åº¦

Stack ç›‘æ§ > Elasticsearch æ¦‚è§ˆ > åˆ†ç‰‡æ´»åŠ¨



ï¼ˆå°±ä¸å†ç²˜è´´å›¾ç‰‡å±•ç¤ºäº†



### ç®¡ç†ç´¢å¼•

> æ³¨æ„ï¼šå¦‚æœå®Œå…¨æŒ‰ç…§æœ¬æ–‡æ¡£åˆ›å»ºéƒ¨ç½²çš„ logstash è‡ªåŠ¨åˆ›å»ºç´¢å¼•åç§°å°±æ˜¯ applogs å¼€å¤´



#### æ£€æŸ¥ç´¢å¼•

é¦–å…ˆéœ€è¦æ£€æŸ¥æ˜¯å¦æˆåŠŸåˆ›å»ºæ—¥å¿—ç´¢å¼•

ç®¡ç† > ç´¢å¼•ç®¡ç† > ç´¢å¼•

![kibana-manager-1](https://image.lkarrie.com/images/2024/10/22/kibana-manager-1.png)



#### ç´¢å¼•æ¨¡å¼

åˆ›å»ºç´¢å¼•æ¨¡å¼

![kibana-manager-5](https://image.lkarrie.com/images/2024/10/22/kibana-manager-5.png)

![kibana-manager-6](https://image.lkarrie.com/images/2024/10/22/kibana-manager-6.png)



#### ç´¢å¼•æ¨¡æ¿

ç´¢å¼•æ¨¡æ¿ä¸»è¦æ˜¯ä¸ºäº†åœ¨åˆ›å»ºç´¢å¼•æ—¶ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®ç›¸å…³åˆ†ç‰‡ã€å‰¯æœ¬ã€æ˜ å°„ç­‰å‚æ•°ï¼Œåˆ™ç”±ç›¸å¯¹åº”çš„æ¨¡æ¿å†…çš„å‚æ•°å†³å®š

ç®¡ç† > ç´¢å¼•ç®¡ç† > ç´¢å¼•æ¨¡æ¿ > æ“ä½œ > ç¼–è¾‘

![kibana-manager-2](https://image.lkarrie.com/images/2024/10/22/kibana-manager-2.png)

##### ç¼–è¾‘æ¨¡æ¿

![kibana-manager-3](https://image.lkarrie.com/images/2024/10/22/kibana-manager-3.png)

##### ç´¢å¼•é…ç½®

æ¯”è¾ƒé‡è¦çš„å°±æ˜¯åˆ†ç‰‡å’Œå‰¯æœ¬æ•°

![kibana-manager-4](https://image.lkarrie.com/images/2024/10/22/kibana-manager-4.png)

ä»…ä¾›å‚è€ƒ

```json
{
  "index": {
    "refresh_interval": "120s",
    "unassigned": {
      "node_left": {
        "delayed_timeout": "5m"
      }
    },
    "number_of_shards": "2",
    "number_of_replicas": "0",
    "merge": {
      "scheduler": {
        "max_thread_count": "1"
      }
    }
  }
}
```

##### è®¾ç½®æ˜ å°„

logstash é»˜è®¤åˆ›å»ºçš„æ˜ å°„è¾ƒä¸ºå¤æ‚

å»ºè®®æŒ‰éœ€è°ƒæ•´æ–‡æ¡£çš„å­—æ®µç±»å‹

![kibana-manager-7](https://image.lkarrie.com/images/2024/10/22/kibana-manager-7.png)

ä»…ä¾›å‚è€ƒ

```json
{
  "properties": {
    "app": {
      "type": "keyword"
    },
    "cluster": {
      "type": "keyword"
    },
    "logpath": {
      "type": "text",
      "fields": {
        "keyword": {
          "type": "keyword"
        }
      }
    },
    "pod": {
      "type": "keyword"
    },
    "subsystem": {
      "type": "keyword"
    },
    "loghost": {
      "type": "keyword"
    },
    "message": {
      "type": "text"
    },
    "type": {
      "type": "keyword"
    },
    "tags": {
      "type": "keyword"
    },
    "@timestamp": {
      "type": "date"
    },
    "system": {
      "type": "keyword"
    },
    "remote_ip": {
      "type": "ip"
    },
    "loglevel": {
      "type": "keyword"
    },
    "logtime": {
      "type": "text"
    }
  }
}
```



### å¸¸ç”¨é›†ç¾¤ç®¡ç†åœºæ™¯

> è¿™é‡Œé›†ç¾¤ç®¡ç† ä¸»è¦æŒ‡ ä½¿ç”¨ Kibana å¼€å‘å·¥å…·çš„ Console ä¸­ï¼Œ å¯¹ ES é›†ç¾¤è¿›è¡Œä¸€äº›ç»´æŠ¤å’Œç®¡ç†å·¥ä½œ

![kibana-devtool](https://image.lkarrie.com/images/2024/10/22/kibana-devtool.png)



#### é›†ç¾¤è®¾ç½®ç®¡ç†

```console
# æŸ¥çœ‹è®¾ç½®
GET _cluster/settings
# æŸ¥çœ‹è®¾ç½® åŒ…å«é»˜è®¤å€¼
GET _cluster/settings?include_defaults
# å¦‚æœä¸ä½¿ç”¨ kibana debugå·¥å…· ä½¿ç”¨ curl å»ºè®®å¢åŠ  &pretty å‚æ•°ä½¿jsonåŒ…å«æ¢è¡Œç¬¦ è¿”å›ç»“æœå¯è¯»
curl "http://127.0.0.1:9200/_cluster/settings?include_defaults&pretty"

# æŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶æ€
# é›†ç¾¤çš„å¥åº·çŠ¶å†µä¸º yellow åˆ™è¡¨ç¤ºå…¨éƒ¨ä¸»åˆ†ç‰‡éƒ½æ­£å¸¸è¿è¡Œï¼ˆé›†ç¾¤å¯ä»¥æ­£å¸¸æœåŠ¡æ‰€æœ‰è¯·æ±‚ï¼‰ï¼Œä½†æ˜¯ å‰¯æœ¬ åˆ†ç‰‡æ²¡æœ‰å…¨éƒ¨å¤„åœ¨æ­£å¸¸çŠ¶æ€
GET _cluster/health

# æ›´æ–°é›†ç¾¤è®¾ç½®
# persistent æ˜¯æ°¸ä¹…ç­–ç•¥ é‡å¯ä¸å¤±æ•ˆ
# transient æ˜¯ä¸´æ—¶ç­–ç•¥ é‡å¯å¤±æ•ˆ
# ä¼˜å…ˆçº§ Transient settings > Persistent settings > command-line settings > config file settings
# å»ºè®® è®¾ç½®åªè®¾ç½® æ°¸ä¹…ç­–ç•¥ä¸€ç§
PUT _cluster/settings
{
    "persistent": {
      "cluster.routing.allocation.enable": "all",
      "cluster.routing.rebalance.enable": "all"
    },
    "transient": {
      "cluster.routing.allocation.enable": "all",
      "cluster.routing.rebalance.enable": "all"
    }
}

# å–æ¶ˆè®¾ç½®
# å¯¹åº”é…ç½®æ”¹ä¸º null é‡æ–°PUT
PUT _cluster/settings
{
    "persistent": {
      "cluster.routing.allocation.enable": null,
      "cluster.routing.rebalance.enable": null
    },
    "transient": {
      "cluster.routing.allocation.enable": null,
      "cluster.routing.rebalance.enable": null
    }
}
```



#### é›†ç¾¤åˆ†ç‰‡è®¾ç½®

å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œä¸»è¦æ¶‰åŠåˆ†ç‰‡çš„åˆ†é…å’Œé‡æ–°å¹³è¡¡ï¼Œå’Œä¸€äº›åˆ†ç‰‡å‚æ•°

[Cluster-level shard allocation and routing settings | Elasticsearch Guide [8.14] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html)

[Size your shards | Elasticsearch Guide [7.17] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/size-your-shards.html)

```console
# è®¾ç½®åˆ†ç‰‡çš„åˆ†é…å’Œé‡æ–°å¹³è¡¡
PUT _cluster/settings
{
    "persistent": {
      "cluster.routing.allocation.enable": "all",
      "cluster.routing.rebalance.enable": "all"
    }
}

# æŸ¥çœ‹å½“å‰é›†ç¾¤æœ‰æ‰€åˆ†ç‰‡æ•°
GET _cluster/stats?filter_path=indices.shards.total

# è®¾ç½®åˆ†ç‰‡ç§»åŠ¨çš„å¹¶å‘æ•°å’ŒèŠ‚ç‚¹åˆ†ç‰‡é™åˆ¶
# é»˜è®¤ 7.x èŠ‚ç‚¹æœ€å¤§åˆ†ç‰‡æ•° 1000
# é›†ç¾¤æœ€å¤§æ€»åˆ†ç‰‡æ•°ä¸º èŠ‚ç‚¹åˆ†ç‰‡é™åˆ¶ * æ´»åŠ¨æ•°æ®èŠ‚ç‚¹æ•°
PUT _cluster/settings
{
    "persistent": {
      "cluster.routing.allocation.node_concurrent_recoveries": "50",
      "cluster.max_shards_per_node": "2000"
    }
}
```



#### æ°´ä½çº¿è°ƒæ•´

ä¸‹é¢ç”¨æ­å»ºçš„æ¨¡æ‹Ÿç¯å¢ƒè¿›è¡Œé›†ç¾¤æ°´ä½è°ƒæ•´æµ‹è¯•

```console
# è®¾ç½®æ°´ä½çº¿
# low: ä½æ°´ä½çº¿ é»˜è®¤85% ç£ç›˜ä½¿ç”¨è¾¾åˆ°85%æ—¶ ç¦æ­¢åˆ†é…æ–°çš„åˆ†ç‰‡
# high: é«˜æ°´ä½çº¿ é»˜è®¤90% ç£ç›˜ä½¿ç”¨è¾¾åˆ°90%æ—¶ ä¼šè‡ªåŠ¨å‡è¡¡åˆ†ç‰‡åˆ°å…¶ä»–èŠ‚ç‚¹
# flood_stage: æ³›æ´ªçº¿ é»˜è®¤95% ç£ç›˜ä½¿ç”¨è¾¾åˆ°95%æ—¶ æ‰€æœ‰åˆ†ç‰‡å˜æˆåªè¯»ï¼Œç¦æ­¢å†™å…¥
# æ³¨æ„ 
# ç›¸å…³æ°´ä½ è¾¾çº¿å
# å‰¯æœ¬åˆ†ç‰‡æ— æ³•å†™å…¥ä¼šå¯¼è‡´é›†ç¾¤ YELLOW
# ä¸»åˆ†ç‰‡æ— æ³•å†™å…¥ä¼šå¯¼è‡´é›†ç¾¤ RAD 

PUT _cluster/settings
{
    "persistent": {
        "cluster.routing.allocation.disk.watermark.low":"80%",
        "cluster.routing.allocation.disk.watermark.high":"85%",
        "cluster.routing.allocation.disk.watermark.flood_stage":"90%"
    }
}

# æ³¨æ„
# æœ€é«˜æ°´ä½çº¿é»˜è®¤åªèƒ½è°ƒæ•´åˆ°95% å¦‚æœéœ€è¦ç»§ç»­è°ƒé«˜è¯¥å€¼ åˆ™éœ€è¦è°ƒæ•´æ³›æ´ªçº¿åå†è°ƒæ•´é«˜æ°´ä½çº¿å’Œä½æ°´ä½çº¿
PUT _cluster/settings
{
    "persistent": {
        "cluster.routing.allocation.disk.watermark.flood_stage":"98%"
    }
}
```



#### ç´¢å¼•ç®¡ç†

ä¸€äº›ç´¢å¼•ç›¸å…³çš„è®¾ç½®

[Index recovery | Elasticsearch Guide [7.5] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/recovery.html)

[Search settings | Elasticsearch Guide [7.17] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/search-settings.html)

```console
# è®¾ç½®ç´¢å¼•æ¢å¤é€Ÿåº¦
PUT _cluster/settings
{
    "persistent": {
        "indices.recovery.max_bytes_per_sec":"80mb"
    }
}

# è®¾ç½®æŸ¥è¯¢ç´¢å¼•èšåˆåˆ†ç»„æ—¶çš„æœ€å¤§æ¡¶æ•°é™åˆ¶
# å¯ä»¥é€šè¿‡æŸ¥è¯¢é»˜è®¤è®¾ç½® æŸ¥çœ‹å½“å‰ç‰ˆæœ¬çš„å€¼ 7.5.1 é»˜è®¤ 10000
PUT _cluster/settings
{
    "persistent": {
         "search.max_buckets" : "15000"
    }
}
```



#### ç´¢å¼•åˆ†ç‰‡è¿ç§»

å½“åˆ†ç‰‡å¤§å°åˆ†é…çš„ä¸åˆç†æ—¶ï¼ˆä¾‹å¦‚å‡ ç™¾Gçš„ç´¢å¼•åˆ†ç‰‡æ•°å¾ˆå°‘ï¼‰ï¼Œä¼šå¯¼è‡´å…¶ä¸­æŸå°æ•°æ®èŠ‚ç‚¹ç£ç›˜å ç”¨è¾ƒé«˜ï¼Œæ­¤æ—¶å°±éœ€è¦è¿›è¡Œåˆ†ç‰‡è¿ç§»æ‰‹åŠ¨è°ƒæ•´å¤§ç´¢å¼•åˆ°ç©ºé—²ç©ºé—´è¾ƒå¤šçš„æ•°æ®èŠ‚ç‚¹ä¸­

è¿˜éœ€è¦æ³¨æ„ å¦‚æœä½ å†æ‰§è¡Œå¤‡ä»½ç´¢å¼•çš„æ“ä½œ **ä¸è¦è¿ç§»æ­£åœ¨å¤‡ä»½çš„ç´¢å¼•**

ä¸‹é¢ç”¨æ­å»ºçš„æ¨¡æ‹Ÿç¯å¢ƒè¿›è¡Œåˆ†ç‰‡è¿ç§»æµ‹è¯•

```console
# è·å–æ‰€æœ‰åˆ†ç‰‡
GET _cat/shards

# è¾“å‡ºæ‰€æœ‰åˆ†ç‰‡ä¿¡æ¯
# åˆ†åˆ«å±•ç¤ºäº† 
# index: åˆ†ç‰‡æ‰€å±çš„ç´¢å¼•å
# shard: åˆ†ç‰‡çš„ç¼–å·
# prirep: åˆ†ç‰‡çš„ç±»å‹ p è¡¨ç¤ºä¸»åˆ†ç‰‡ r è¡¨ç¤ºå‰¯æœ¬åˆ†ç‰‡
# state: åˆ†ç‰‡çš„å½“å‰çŠ¶æ€
# docs: åˆ†ç‰‡ä¸­çš„æ–‡æ¡£æ•°é‡
# store: åˆ†ç‰‡å ç”¨çš„å­˜å‚¨ç©ºé—´å¤§å°
# ip: åˆ†ç‰‡æ‰€åœ¨çš„èŠ‚ç‚¹çš„IPåœ°å€
# node: åˆ†ç‰‡æ‰€åœ¨çš„èŠ‚ç‚¹å
# çœç•¥éƒ¨åˆ† ...
applogs-test-2024.05.24           1 p STARTED    1     7kb 192.168.202.131 ms3
applogs-test-2024.05.24           0 p STARTED    0    230b 192.168.202.131 ms2

# ä»¥ ç´¢å¼• applogs-test-2024.05.24 ç¼–å·ä¸º 1 çš„åˆ†ç‰‡ ä» ms3 è¿ç§»åˆ° ms2 ä¸ºä¾‹
POST /_cluster/reroute
{
    "commands" : [
        {
        "move" : {
            "index" : "applogs-test-2024.05.24",
            "shard" : "1",
            "from_node" : "ms3",
            "to_node" : "ms2"
            }
        }
    ]
}

# è¾“å‡º
# æ³¨æ„è§‚å¯Ÿè¾“å‡º è¿ç§»çš„ç´¢å¼•åˆ†ç‰‡çŠ¶æ€å‡è¢«è°ƒæ•´ä¸ºäº† RELOCATING
# æˆåŠŸè¿ç§»å åˆ†ç‰‡çŠ¶æ€ä¼šæ¢å¤ä¸º STARTED
{
  "acknowledged" : true,
  "state" : {
    # çœç•¥èŠ‚ç‚¹éƒ¨åˆ†è¾“å‡º
    # ...
    "routing_table" : {
      "indices" : {
        "applogs-test-2024.05.24" : {
          "shards" : {
            "1" : [
              {
                "state" : "RELOCATING",
                "primary" : true,
                "node" : "RL77XAW3SSGF8F4L-NEnkw",
                "relocating_node" : "DgSLzoz6QkWeoDBRKeilZQ",
                "shard" : 1,
                "index" : "applogs-test-2024.05.24",
                "expected_shard_size_in_bytes" : 7312,
                "allocation_id" : {
                  "id" : "LQ5EG039Q7S1dvPj1MeXUQ",
                  "relocation_id" : "kVPVi1wHQkqG6mjBKKYMRg"
                }
              }
            ],
            "0" : [
              {
                "state" : "RELOCATING",
                "primary" : true,
                "node" : "DgSLzoz6QkWeoDBRKeilZQ",
                "relocating_node" : "RL77XAW3SSGF8F4L-NEnkw",
                "shard" : 0,
                "index" : "applogs-test-2024.05.24",
                "expected_shard_size_in_bytes" : 283,
                "allocation_id" : {
                  "id" : "LqDERmEkSDiPc2SyEo0XZQ",
                  "relocation_id" : "aV9AT1scQIG7NuM9Gmr18g"
                }
              }
            ]
          }
        },
		# çœç•¥å…¶ä»–ç´¢å¼•è¾“å‡º
      }
    },
    "routing_nodes" : {
      "unassigned" : [ ],
      "nodes" : {
        "DgSLzoz6QkWeoDBRKeilZQ" : [
          {
            "state" : "INITIALIZING",
            "primary" : true,
            "node" : "DgSLzoz6QkWeoDBRKeilZQ",
            "relocating_node" : "RL77XAW3SSGF8F4L-NEnkw",
            "shard" : 1,
            "index" : "applogs-test-2024.05.24",
            "expected_shard_size_in_bytes" : 7312,
            "recovery_source" : {
              "type" : "PEER"
            },
            "allocation_id" : {
              "id" : "kVPVi1wHQkqG6mjBKKYMRg",
              "relocation_id" : "LQ5EG039Q7S1dvPj1MeXUQ"
            }
          },
          {
            "state" : "RELOCATING",
            "primary" : true,
            "node" : "DgSLzoz6QkWeoDBRKeilZQ",
            "relocating_node" : "RL77XAW3SSGF8F4L-NEnkw",
            "shard" : 0,
            "index" : "applogs-test-2024.05.24",
            "expected_shard_size_in_bytes" : 283,
            "allocation_id" : {
              "id" : "LqDERmEkSDiPc2SyEo0XZQ",
              "relocation_id" : "aV9AT1scQIG7NuM9Gmr18g"
            }
          },
          ## çœç•¥å…¶ä»–è¾“å‡º
        ],
        "RL77XAW3SSGF8F4L-NEnkw" : [
          {
            "state" : "RELOCATING",
            "primary" : true,
            "node" : "RL77XAW3SSGF8F4L-NEnkw",
            "relocating_node" : "DgSLzoz6QkWeoDBRKeilZQ",
            "shard" : 1,
            "index" : "applogs-test-2024.05.24",
            "expected_shard_size_in_bytes" : 7312,
            "allocation_id" : {
              "id" : "LQ5EG039Q7S1dvPj1MeXUQ",
              "relocation_id" : "kVPVi1wHQkqG6mjBKKYMRg"
            }
          },
          {
            "state" : "INITIALIZING",
            "primary" : true,
            "node" : "RL77XAW3SSGF8F4L-NEnkw",
            "relocating_node" : "DgSLzoz6QkWeoDBRKeilZQ",
            "shard" : 0,
            "index" : "applogs-test-2024.05.24",
            "expected_shard_size_in_bytes" : 283,
            "recovery_source" : {
              "type" : "PEER"
            },
            "allocation_id" : {
              "id" : "aV9AT1scQIG7NuM9Gmr18g",
              "relocation_id" : "LqDERmEkSDiPc2SyEo0XZQ"
            }
          },
		  # çœç•¥å…¶ä»–è¾“å‡º	
        ]
      }
    },
    "security_tokens" : { }
  }
}

# å†æ¬¡è§‚å¯Ÿåˆ†ç‰‡
GET _cat/shards

# è¾“å‡º
# å¯ä»¥è§‚å¯Ÿåˆ° ä¸»åˆ†ç‰‡å·²ç»åˆ‡æ¢åˆ° ms2
# ç”±äºESä¼šè‡ªåŠ¨å¹³è¡¡åˆ†ç‰‡æ•° æœªè¢«è¿ç§»çš„åˆ†ç‰‡0ä¼šè¢«è‡ªåŠ¨ä»ms2è¿ç§»åˆ°ms3
# å¯ä» Stack Monitoring > Elasticsearch æ¦‚è§ˆ > åˆ†ç‰‡æ´»åŠ¨ > å·²ç»å®Œæˆæ¢å¤ éªŒè¯åˆ†ç‰‡æ´»åŠ¨ å¦‚ä¸‹å›¾
# çœç•¥éƒ¨åˆ†...
applogs-test-2024.05.24           1 p STARTED     1   7.1kb 192.168.202.131 ms2
applogs-test-2024.05.24           0 p STARTED     0    283b 192.168.202.131 ms3
```

![kibana-shard-move](https://image.lkarrie.com/images/2024/10/22/kibana-shard-move.png)



#### æ»šåŠ¨é‡å¯

å®˜æ–¹æ–‡æ¡£å¯¹é‡å¯æœ‰è¾ƒè¯¦ç»†çš„è¯´æ˜ï¼š[Full-cluster restart and rolling restart | Elasticsearch Guide 7.5\] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/restart-cluster.html)

å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£

ä¸‹é¢æ˜¯ä¸€äº›è‡ªå·±çš„å®è·µæ€»ç»“

æ»šåŠ¨é‡å¯å‰ï¼Œå»ºè®®åœæ­¢æ‰€æœ‰çš„ logstash å’Œ kibanaï¼Œç„¶åå¯¹é›†ç¾¤è¿›è¡Œè°ƒæ•´

é›†ç¾¤æ»šåŠ¨é‡å¯å‰éœ€ç¦ç”¨åˆ†ç‰‡è‡ªåŠ¨åˆ†é…ï¼Œè®¾ç½® cluster.routing.allocation.enable ä¸º none

å¦åˆ™èŠ‚ç‚¹åœæ­¢åå½“å‰èŠ‚ç‚¹çš„åˆ†ç‰‡ä¼šè‡ªåŠ¨åˆ†é…åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šï¼Œæœ¬èŠ‚ç‚¹å¯åŠ¨åéœ€è¦ç­‰å…¶ä»–èŠ‚ç‚¹RECOVERINGåæ‰ä¼šRELOCATINGï¼Œä¹Ÿå°±æ˜¯åˆ†ç‰‡åœ¨å…¶ä»–èŠ‚ç‚¹æ¢å¤ååˆä¼šè½¬ç§»å›æ¥

```console
PUT _cluster/settings
{
    "transient": {
        "cluster.routing.allocation.enable":"none"
    }
}
```

æ‰§è¡ŒåŒæ­¥åˆ·æ–°ï¼Œä½¿å†…å­˜æ•°æ®è½ç›˜

```console
POST _flush/synced
```

æ‰§è¡Œå®Œæ¯•åå¼€å³å¯å¼€å§‹é‡å¯ESèŠ‚ç‚¹ å»ºè®®ä» æ•°æ®èŠ‚ç‚¹ -> åè°ƒèŠ‚ç‚¹ -> ä¸»èŠ‚ç‚¹çš„é¡ºåºé‡å¯

æ‰§è¡Œåœæ­¢å½“å‰èŠ‚ç‚¹ ES

æ‰§è¡Œå¯åŠ¨å½“å‰èŠ‚ç‚¹ ES

ç¡®è®¤èŠ‚ç‚¹åŠ å…¥ ES é›†ç¾¤

```console
GET _cat/nodes
```

ç¡®è®¤é‡å¯èŠ‚ç‚¹åŠ å…¥é›†ç¾¤åï¼Œå†æ¬¡å¼€å¯åˆ†ç‰‡è‡ªåŠ¨è¿ç§»

```console
PUT _cluster/settings
{
    "transient": {
        "cluster.routing.allocation.enable":"all"
    }
}
```

ç­‰å¾…é›†ç¾¤æ¢å¤

æ³¨æ„ï¼š**éœ€è¦å½“é‡å¯èŠ‚ç‚¹å®Œå…¨æ¢å¤æ­£å¸¸**ï¼Œå†è¿›è¡Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„é‡å¯æ“ä½œ

```console
# å¯ä»¥é€šè¿‡å¦‚ä¸‹çš„ API ç¡®è®¤èŠ‚ç‚¹å’Œç´¢å¼•ä¿¡æ¯
GET _cat/health
GET _cat/nodes
GET _cluster/health
GET _cat/recovery
```

é‡å¤ä¸Šè¿°çš„æ­¥éª¤

é¦–å…ˆç¦ç”¨åˆ†ç‰‡è¿ç§» > æ‰§è¡ŒåŒæ­¥åˆ·æ–° > é‡å¯ES > æ‰“å¼€åˆ†ç‰‡è¿ç§» > ç­‰å¾…é›†ç¾¤Green

**æ³¨æ„**ï¼šåœ¨å¤§æ•°æ®é‡å’ŒESé›†ç¾¤è§„æ¨¡è¾ƒå¤§æ—¶ï¼Œæ»šåŠ¨é‡å¯æ•´ä¸ªESé›†ç¾¤çš„è¿‡ç¨‹ä¼šéå¸¸ç¼“æ…¢ï¼Œæ—¥å¿—æ”¶é›†çš„åœºæ™¯ä¸‹å¯ä»¥ç¼©çŸ­æ—¶é—´ï¼Œåœæ­¢ESé›†ç¾¤ä¸Šä¸‹æ¸¸åï¼Œè¿›è¡Œå…¨éƒ¨åœæ­¢å…¨éƒ¨å¯åŠ¨çš„æ“ä½œ



